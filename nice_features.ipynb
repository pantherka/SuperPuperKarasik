{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import os\n",
    "import gzip\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import chain        \n",
    "from contextlib import ExitStack \n",
    "import time\n",
    "import json\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from multiprocessing.dummy import Lock as ThreadLock \n",
    "from multiprocessing.dummy import Value as ThreadValue\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pymorphy2\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import cosine\n",
    "from multiprocessing.dummy import Lock\n",
    "from gensim import corpora\n",
    "from gensim.summarization import bm25\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "# from pytorch_transformers import BertTokenizer, BertConfig\n",
    "# from transformers import  BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmerR = SnowballStemmer('russian')\n",
    "stemmerE = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_for_titles(line):\n",
    "    data = line.split('\\t', 1)\n",
    "    doc_id = int(data[0])\n",
    "    if len(data[1]) == 1:\n",
    "        title = ''\n",
    "    else:\n",
    "        title = data[1]\n",
    "    doc_to_title[doc_id] = title[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with codecs.open('docs_titles.tsv', 'r', 'utf8') as f:\n",
    "    next(f)\n",
    "    with ThreadPool(10) as pool:\n",
    "        pool.map(inp_for_titles, f)\n",
    "print(len(doc_to_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words([\"russian\", \"english\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parser_for_titles(ID):\n",
    "    title = (doc_to_title[ID])\n",
    "    title = title.lower()\n",
    "    words = [stemmerR.stem(stemmerE.stem(word)) for word in re.sub('[^a-zа-я0-9]', ' ', title).split()]\n",
    "    with lock:\n",
    "        vec[ID] = ' '.join([word for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parser_for_titles_without_stemming(ID):\n",
    "    title = (doc_to_title[ID])\n",
    "    title = title.lower()\n",
    "    words = [word for word in re.sub('[^a-zа-я0-9]', ' ', title).split()]\n",
    "    with lock:\n",
    "        vec[ID] = ' '.join([word for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parser_for_text(ID):\n",
    "    with lock:\n",
    "        text_id = df[df.id == ID].text.values\n",
    "    text_id = text_id[0]\n",
    "    stemmed_text = [stemmerR.stem(stemmerE.stem(word)) for word in text_id.split(' ')[:512]]\n",
    "    with lock:\n",
    "        vector_of_text[str(ID)] = ' '.join([word for word in stemmed_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv('/Users/egor/Desktop/Техносфера/MachineLearning/project/data/project.csv', encoding='utf-8', chunksize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for df in df_iter:\n",
    "    df.fillna(' ')\n",
    "    vector_of_text = {}\n",
    "    idx = df.id.values\n",
    "    with ThreadPool(10) as pool:\n",
    "        pool.map(Parser_for_text, idx)\n",
    "    with open('texts/text_stemmed_part_{:05d}.json'.format(i), mode='wb') as f_json:\n",
    "        f_json = codecs.getwriter('utf8')(f_json)\n",
    "        record = json.dumps(vector_of_text, ensure_ascii=False)\n",
    "        print(record, file=f_json)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "есть 57 файлов с индексами страниц по 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = {}\n",
    "with ThreadPool(10) as pool:\n",
    "    pool.map(Parser_for_titles_without_stemming, list(range(1,28027)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titles_without_stemming.json', 'w', encoding='utf8') as file:\n",
    "    json.dump(vec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titles_stemming.json', 'w', encoding='utf8') as file:\n",
    "    json.dump(vec, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Застемил заголовки - уже прекрасно!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мутим фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.fasttext import load_facebook_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взяли заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('titles_stemming.json', 'r', encoding='utf8') as file:\n",
    "    vec = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for value in vec.values():\n",
    "    sentences.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fasttext = FastText('/Users/egor/Desktop/Техносфера/MachineLearning/project/ft_freqprune_400K_100K_pq_300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28026"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'м б аншин центр репродукц и генетик фертимед г москв'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = sentences[0]\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_fasttext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-74d44d68685a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_fasttext' is not defined"
     ]
    }
   ],
   "source": [
    "len(model_fasttext.wv[first])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем сделать общий файл с эмеддингами текстов.. не просто так же их парсили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем эмбединги и запоминаем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir('texts_57_json')\n",
    "texts_embeddings = {}\n",
    "texts_embeding_to_json = {}\n",
    "for f_name in filenames:\n",
    "    file_n = 'texts_57_json/' + f_name\n",
    "    with open(file_n, mode='r') as file:\n",
    "        d = json.load(file)  # все тексты \n",
    "        for key, val in d.items():\n",
    "            embedding = model_fasttext.wv[val]\n",
    "            embedding_string = tuple(map(str, embedding))\n",
    "            texts_embeddings[key] = embedding\n",
    "            texts_embeding_to_json[key] = embedding_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хочу сделать Tf-Idf векторизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись в файл стринговых эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем прочитать эмбеддинги - не забудь перевести в float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('texts_embeddings.json', 'r', encoding='utf8') as file:\n",
    "    texts_embedding_from_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in texts_embedding_from_json.items():\n",
    "    embedding = np.array(list(map(float, texts_embedding_from_json[key])))\n",
    "    texts_embedding_from_json[key] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если фасттекст применять к текстам после стемминга, результат получается лучше почему-то."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для заголовков:\n",
    "1) Метки кластеров внутри группы\n",
    "2) Силуэт для объекта группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Import:\n",
    "    def __init__(self):\n",
    "        self.doc_to_title = {}\n",
    "        #self.model_fasttext = FastText('/Users/egor/Desktop/Техносфера/MachineLearning/project/ft_freqprune_400K_100K_pq_300.bin')\n",
    "        with open('docs_titles.tsv', encoding='utf-8') as f:\n",
    "            for num_line, line in enumerate(f):\n",
    "                if num_line == 0:\n",
    "                    continue\n",
    "                data = line.strip().split('\\t', 1)\n",
    "                doc_id = int(data[0])\n",
    "                if len(data) == 1:\n",
    "                    title = ''\n",
    "                else:\n",
    "                    title = data[1]\n",
    "                self.doc_to_title[doc_id] = title\n",
    "        #self.top_k_cosine_titles = 3 # k ближайших косинусных расстояний для заголовков\n",
    "        #self.best_docs_cnt = 10 # K самых похожих заголовков\n",
    "        self.top_k_cosine_tf_idf = 10\n",
    "        vec['0'] = ''\n",
    "        self.doc_to_vec = TfidfVectorizer().fit_transform([vec[str(i)] for i in range(len(vec))])\n",
    "        self.new_features = 10\n",
    "        #self.top_k_cosine_texts = 20 # k ближайших косинусных расстояний для заголовков\n",
    "    \n",
    "    def make_train(self):\n",
    "        train_data = pd.read_csv('train_groups.csv', encoding='utf-8')\n",
    "        traingroups_titledata = {}\n",
    "        for i in range(len(train_data)):\n",
    "            new_doc = train_data.iloc[i]\n",
    "            doc_group = new_doc['group_id']\n",
    "            doc_id = new_doc['doc_id']\n",
    "            target = new_doc['target']\n",
    "            title = self.doc_to_title[doc_id]\n",
    "            if doc_group not in traingroups_titledata:\n",
    "                traingroups_titledata[doc_group] = []\n",
    "            traingroups_titledata[doc_group].append((doc_id, title, target))\n",
    "        \n",
    "        svd = TruncatedSVD(n_components=5)\n",
    "        y_train = []\n",
    "        X_train = []\n",
    "        groups_train = []\n",
    "        for new_group in traingroups_titledata:\n",
    "            docs = traingroups_titledata[new_group]\n",
    "            for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "                y_train.append(target_id)\n",
    "                groups_train.append(new_group)\n",
    "                all_dist = []\n",
    "                words = set(title.strip().split())\n",
    "                for j in range(0, len(docs)):\n",
    "                    if k == j:\n",
    "                        continue\n",
    "                    doc_id_j, title_j, target_j = docs[j]\n",
    "                    words_j = set(title_j.strip().split())\n",
    "                    all_dist.append(len(words.intersection(words_j)))\n",
    "                X_train.append(sorted(all_dist, reverse=True)[0:15]    )\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        groups_train = np.array(groups_train)\n",
    "        \n",
    "        # Класстеризация внутри группы:\n",
    "        i = 0\n",
    "        My_X = np.zeros((train_data.shape[0], self.top_k_cosine_tf_idf + self.new_features)) # кол-во новых фичей\n",
    "        groups = train_data.groupby('group_id')\n",
    "        rand_index = []\n",
    "        for group_id, group_indx in groups.groups.items():\n",
    "            group = train_data.iloc[group_indx]\n",
    "            \n",
    "            docs_id = group.doc_id.values\n",
    "            # сначала заберем все файлы из группы\n",
    "            embedded_texts = []\n",
    "            group_titles = []\n",
    "            for idx in docs_id:\n",
    "                group_titles.append(vec[str(idx)])\n",
    "                embedded_texts.append(texts_embedding_from_json[str(idx)])\n",
    "                \n",
    "            \n",
    "            '''\n",
    "            # BM25\n",
    "            best_docs = []\n",
    "            texts = [doc.split() for doc in group_titles]\n",
    "            dictionary = corpora.Dictionary(texts)\n",
    "            corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "            bm25_obj = bm25.BM25(corpus)\n",
    "            for title in group_titles:\n",
    "                query = title\n",
    "                query_doc = dictionary.doc2bow(query.split())\n",
    "                scores = bm25_obj.get_scores(query_doc)\n",
    "                best_docs.append(sorted(range(len(scores)), key=lambda i: scores[i])[-self.best_docs_cnt:])\n",
    "            '''\n",
    "            #\n",
    "            # embedded_titles = model_fasttext.wv[group_titles]\n",
    "            tf_idf_vec = self.doc_to_vec[group.doc_id]\n",
    "            svd_vec = svd.fit_transform(tf_idf_vec)\n",
    "            targets = group.target.values\n",
    "            model_titles = DBSCAN(0.6, metric=\"cosine\", min_samples=8)\n",
    "            labels_titles = model_titles.fit_predict(tf_idf_vec)\n",
    "            '''\n",
    "            if np.unique(labels_titles).size > 1:\n",
    "                silhouette = silhouette_samples(embedded_titles, labels_titles)\n",
    "            else:\n",
    "                silhouette = np.ones(len(labels_titles)) # если всего один кластер\n",
    "            model_texts = DBSCAN(0.1, metric=\"cosine\", min_samples=4)\n",
    "            labels_texts = model_texts.fit_predict(embedded_texts)\n",
    "            # добавим фичи из расстояний для эмбеддингов\n",
    "            # получим матрицу из попарных расстояний\n",
    "            cos_distances = cosine_similarity(embedded_titles)\n",
    "            sorted_dist = np.apply_along_axis(np.sort, axis=1, arr=cos_distances)[:, ::-1]\n",
    "            cos_features = sorted_dist[:, 1: self.top_k_cosine_titles + 1]\n",
    "            '''\n",
    "            # добавим фичи из расстояний для tf-idf\n",
    "            cos_distances = cosine_similarity(tf_idf_vec)\n",
    "            sorted_dist = np.apply_along_axis(np.sort, axis=1, arr=cos_distances)[:, ::-1]\n",
    "            tf_idf_features = sorted_dist[:, 1: self.top_k_cosine_tf_idf + 1]\n",
    "            \n",
    "            svd_cos_distances = cosine_similarity(svd_vec)\n",
    "            svd_sorted_dist = np.apply_along_axis(np.sort, axis=1, arr=svd_cos_distances)[:, ::-1]\n",
    "            svd_features = svd_sorted_dist[:, 1: self.new_features + 1]\n",
    "            \n",
    "            My_X[i: i + group_indx.size, :self.top_k_cosine_tf_idf] = tf_idf_features\n",
    "            #My_X[i: i + group_indx.size, -1] = labels_titles\n",
    "            My_X[i: i + group_indx.size, self.top_k_cosine_tf_idf: \n",
    "                self.top_k_cosine_tf_idf + self.new_features] = svd_features\n",
    "            # валидация дала DBSCAN(0.6, metric=\"cosine\", min_samples=8)\n",
    "            #My_X[i: i + group_indx.size, -1] = labels_texts\n",
    "            i += group_indx.size\n",
    "        \n",
    "        \n",
    "        X_train = np.concatenate((X_train, My_X), axis=1)\n",
    "        return X_train, y_train, groups_train\n",
    "    \n",
    "    def make_test(self):\n",
    "        test_data = pd.read_csv('test_groups.csv', encoding='utf-8')\n",
    "        testgroups_titledata = {}\n",
    "        for i in range(len(test_data)):\n",
    "            new_doc = test_data.iloc[i]\n",
    "            doc_group = new_doc['group_id']\n",
    "            doc_id = new_doc['doc_id']\n",
    "            title = self.doc_to_title[doc_id]\n",
    "            if doc_group not in testgroups_titledata:\n",
    "                testgroups_titledata[doc_group] = []\n",
    "            testgroups_titledata[doc_group].append((doc_id, title))\n",
    "        \n",
    "        svd = TruncatedSVD(n_components=5)\n",
    "        X_test = []\n",
    "        groups_test = []\n",
    "        for new_group in testgroups_titledata:\n",
    "            docs = testgroups_titledata[new_group]\n",
    "            for k, (doc_id, title) in enumerate(docs):\n",
    "                groups_test.append(new_group)\n",
    "                all_dist = []\n",
    "                words = set(title.strip().split())\n",
    "                for j in range(0, len(docs)):\n",
    "                    if k == j:\n",
    "                        continue\n",
    "                    doc_id_j, title_j = docs[j]\n",
    "                    words_j = set(title_j.strip().split())\n",
    "                    all_dist.append(len(words.intersection(words_j)))\n",
    "                X_test.append(sorted(all_dist, reverse=True)[0:15])\n",
    "        X_test = np.array(X_test)\n",
    "        \n",
    "        i = 0\n",
    "        My_X = np.zeros((test_data.shape[0], self.top_k_cosine_tf_idf + self.new_features)) # кол-во новых фичей\n",
    "        groups = test_data.groupby('group_id')\n",
    "        for group_id, group_indx in groups.groups.items():\n",
    "            group = test_data.iloc[group_indx]\n",
    "            docs_id = group.doc_id.values\n",
    "            group_titles = []\n",
    "            embedded_texts = []\n",
    "            for idx in docs_id:\n",
    "                group_titles.append(vec[str(idx)])\n",
    "                embedded_texts.append(texts_embedding_from_json[str(idx)])\n",
    "                \n",
    "            \n",
    "            # embedded_titles = model_fasttext.wv[group_titles]\n",
    "            tf_idf_vec = self.doc_to_vec[group.doc_id]\n",
    "            svd_vec = svd.fit_transform(tf_idf_vec)\n",
    "            model_titles = DBSCAN(0.6, metric=\"cosine\", min_samples=8)\n",
    "            labels_titles = model_titles.fit_predict(tf_idf_vec)\n",
    "            '''\n",
    "            if np.unique(labels_titles).size > 1:\n",
    "                silhouette = silhouette_samples(embedded_titles, labels_titles)\n",
    "            else:\n",
    "                silhouette = np.ones(len(labels_titles)) # если всего один кластер\n",
    "            model_texts = DBSCAN(0.1, metric=\"cosine\", min_samples=4)\n",
    "            labels_texts = model_texts.fit_predict(embedded_texts)\n",
    "            cos_distances = cosine_similarity(embedded_titles)\n",
    "            sorted_dist = np.apply_along_axis(np.sort, axis=1, arr=cos_distances)[:, ::-1]\n",
    "            cos_features = sorted_dist[:, 1: self.top_k_cosine_titles + 1]\n",
    "            '''\n",
    "            # добавим фичи из расстояний для tf-idf\n",
    "            cos_distances = cosine_similarity(tf_idf_vec)\n",
    "            sorted_dist = np.apply_along_axis(np.sort, axis=1, arr=cos_distances)[:, ::-1]\n",
    "            tf_idf_features = sorted_dist[:, 1: self.top_k_cosine_tf_idf + 1]\n",
    "            \n",
    "            svd_cos_distances = cosine_similarity(svd_vec)\n",
    "            svd_sorted_dist = np.apply_along_axis(np.sort, axis=1, arr=svd_cos_distances)[:, ::-1]\n",
    "            svd_features = svd_sorted_dist[:, 1: self.new_features + 1]\n",
    "            \n",
    "            \n",
    "            My_X[i: i + group_indx.size, :self.top_k_cosine_tf_idf] = tf_idf_features\n",
    "#             My_X[i: i + group_indx.size, -1] = labels_titles\n",
    "            My_X[i: i + group_indx.size, self.top_k_cosine_tf_idf: \n",
    "                self.top_k_cosine_tf_idf + self.new_features] = svd_features\n",
    "            #My_X[i: i + group_indx.size, self.top_k_cosine_tf_idf: \n",
    "            #     self.top_k_cosine_tf_idf + self.top_k_cosine_titles] = cos_features\n",
    "            #My_X[i: i + group_indx.size, :self.top_k_cosine_titles] = cos_features\n",
    "            #My_X[i: i + group_indx.size, -1] = labels_texts\n",
    "            i += group_indx.size\n",
    "            \n",
    "            #My_X[i: i + group_indx.size, self.top_k_cosine_titles:self.top_k_cosine_titles\n",
    "            #    + self.top_k_cosine_texts] = cos_features_texts\n",
    "            # валидация дала DBSCAN(0.6, metric=\"cosine\", min_samples=8)\n",
    "        \n",
    "        X_test = np.concatenate((X_test, My_X), axis=1)\n",
    "        groups_test = np.array(groups_test)\n",
    "        return X_test, groups_test, test_data['pair_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация для кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидация для заголовков дала DBSCAN(0.6, metric=\"cosine\", min_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "importer = Import()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, groups_train = importer.make_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, groups_test, pair_ids = importer.make_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 35)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 35)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.        , 2.        , 2.        , 2.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.70656332, 0.6970693 , 0.62324526, 0.58965499, 0.58099242,\n",
       "       0.57786371, 0.54620394, 0.51634023, 0.43289396, 0.42958136,\n",
       "       0.99801683, 0.98619192, 0.9685004 , 0.93552901, 0.93526397,\n",
       "       0.90359191, 0.88457749, 0.87763724, 0.81671146, 0.814454  ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.93613643, 0.77186271, 0.66278083, 0.64052685, 0.63320168,\n",
       "       0.60131956, 0.59988497, 0.59492016, 0.58890143, 0.57642028])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модельки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import BaseEstimator\n",
    "from statistics import mean\n",
    "from gensim.models import FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import catboost\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sk = StandardScaler()\n",
    "X_train_sk = my_sk.fit_transform(X_train)\n",
    "X_test_sk = my_sk.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator(X_train, X_test, num_model):\n",
    "    indices = np.array([])\n",
    "    length = X_train.shape[1]\n",
    "    features = np.arange(length)\n",
    "    np.random.shuffle(features)\n",
    "    for i in range(num_model):\n",
    "        ind = np.random.randint(0, length, length)\n",
    "        ind = np.unique(np.append(ind, features[i * (length // num_model) : (i + 1) * (length // num_model + 1)]))\n",
    "        yield X_train[:, ind], X_test[:, ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_e_1 = RandomForestClassifier(max_depth=10, n_estimators=150)\n",
    "clf_e_2 = ExtraTreesClassifier(max_depth=15)\n",
    "clf_e_4 = catboost.CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.029437\n",
      "0:\tlearn: 0.6662263\ttotal: 147ms\tremaining: 2m 26s\n",
      "1:\tlearn: 0.6413595\ttotal: 206ms\tremaining: 1m 42s\n",
      "2:\tlearn: 0.6192100\ttotal: 248ms\tremaining: 1m 22s\n",
      "3:\tlearn: 0.5997207\ttotal: 269ms\tremaining: 1m 6s\n",
      "4:\tlearn: 0.5814900\ttotal: 318ms\tremaining: 1m 3s\n",
      "5:\tlearn: 0.5632770\ttotal: 350ms\tremaining: 58s\n",
      "6:\tlearn: 0.5474738\ttotal: 392ms\tremaining: 55.7s\n",
      "7:\tlearn: 0.5342222\ttotal: 414ms\tremaining: 51.4s\n",
      "8:\tlearn: 0.5208453\ttotal: 431ms\tremaining: 47.5s\n",
      "9:\tlearn: 0.5078231\ttotal: 458ms\tremaining: 45.4s\n",
      "10:\tlearn: 0.4965615\ttotal: 515ms\tremaining: 46.3s\n",
      "11:\tlearn: 0.4854964\ttotal: 530ms\tremaining: 43.7s\n",
      "12:\tlearn: 0.4757022\ttotal: 555ms\tremaining: 42.1s\n",
      "13:\tlearn: 0.4656711\ttotal: 574ms\tremaining: 40.4s\n",
      "14:\tlearn: 0.4570486\ttotal: 596ms\tremaining: 39.1s\n",
      "15:\tlearn: 0.4503162\ttotal: 624ms\tremaining: 38.4s\n",
      "16:\tlearn: 0.4439267\ttotal: 640ms\tremaining: 37s\n",
      "17:\tlearn: 0.4380234\ttotal: 690ms\tremaining: 37.7s\n",
      "18:\tlearn: 0.4321969\ttotal: 703ms\tremaining: 36.3s\n",
      "19:\tlearn: 0.4263477\ttotal: 717ms\tremaining: 35.1s\n",
      "20:\tlearn: 0.4205872\ttotal: 735ms\tremaining: 34.3s\n",
      "21:\tlearn: 0.4160662\ttotal: 761ms\tremaining: 33.8s\n",
      "22:\tlearn: 0.4116208\ttotal: 777ms\tremaining: 33s\n",
      "23:\tlearn: 0.4070715\ttotal: 791ms\tremaining: 32.2s\n",
      "24:\tlearn: 0.4027606\ttotal: 809ms\tremaining: 31.5s\n",
      "25:\tlearn: 0.3984536\ttotal: 843ms\tremaining: 31.6s\n",
      "26:\tlearn: 0.3946473\ttotal: 860ms\tremaining: 31s\n",
      "27:\tlearn: 0.3917784\ttotal: 907ms\tremaining: 31.5s\n",
      "28:\tlearn: 0.3880974\ttotal: 923ms\tremaining: 30.9s\n",
      "29:\tlearn: 0.3853697\ttotal: 939ms\tremaining: 30.4s\n",
      "30:\tlearn: 0.3823463\ttotal: 952ms\tremaining: 29.8s\n",
      "31:\tlearn: 0.3794451\ttotal: 966ms\tremaining: 29.2s\n",
      "32:\tlearn: 0.3769728\ttotal: 983ms\tremaining: 28.8s\n",
      "33:\tlearn: 0.3746397\ttotal: 1.01s\tremaining: 28.7s\n",
      "34:\tlearn: 0.3724242\ttotal: 1.03s\tremaining: 28.4s\n",
      "35:\tlearn: 0.3701905\ttotal: 1.07s\tremaining: 28.6s\n",
      "36:\tlearn: 0.3681253\ttotal: 1.08s\tremaining: 28.1s\n",
      "37:\tlearn: 0.3665302\ttotal: 1.11s\tremaining: 28s\n",
      "38:\tlearn: 0.3649431\ttotal: 1.12s\tremaining: 27.7s\n",
      "39:\tlearn: 0.3634725\ttotal: 1.14s\tremaining: 27.4s\n",
      "40:\tlearn: 0.3621229\ttotal: 1.16s\tremaining: 27.1s\n",
      "41:\tlearn: 0.3607883\ttotal: 1.18s\tremaining: 27s\n",
      "42:\tlearn: 0.3596216\ttotal: 1.2s\tremaining: 26.8s\n",
      "43:\tlearn: 0.3584023\ttotal: 1.22s\tremaining: 26.5s\n",
      "44:\tlearn: 0.3569795\ttotal: 1.25s\tremaining: 26.6s\n",
      "45:\tlearn: 0.3557399\ttotal: 1.3s\tremaining: 27s\n",
      "46:\tlearn: 0.3547162\ttotal: 1.35s\tremaining: 27.4s\n",
      "47:\tlearn: 0.3537618\ttotal: 1.39s\tremaining: 27.6s\n",
      "48:\tlearn: 0.3525585\ttotal: 1.42s\tremaining: 27.5s\n",
      "49:\tlearn: 0.3517467\ttotal: 1.45s\tremaining: 27.6s\n",
      "50:\tlearn: 0.3509634\ttotal: 1.49s\tremaining: 27.8s\n",
      "51:\tlearn: 0.3499534\ttotal: 1.52s\tremaining: 27.8s\n",
      "52:\tlearn: 0.3493655\ttotal: 1.54s\tremaining: 27.6s\n",
      "53:\tlearn: 0.3483373\ttotal: 1.56s\tremaining: 27.3s\n",
      "54:\tlearn: 0.3473348\ttotal: 1.6s\tremaining: 27.5s\n",
      "55:\tlearn: 0.3465469\ttotal: 1.65s\tremaining: 27.9s\n",
      "56:\tlearn: 0.3459448\ttotal: 1.69s\tremaining: 27.9s\n",
      "57:\tlearn: 0.3449089\ttotal: 1.72s\tremaining: 27.9s\n",
      "58:\tlearn: 0.3440317\ttotal: 1.74s\tremaining: 27.7s\n",
      "59:\tlearn: 0.3433687\ttotal: 1.77s\tremaining: 27.7s\n",
      "60:\tlearn: 0.3428922\ttotal: 1.81s\tremaining: 27.9s\n",
      "61:\tlearn: 0.3423483\ttotal: 1.86s\tremaining: 28.2s\n",
      "62:\tlearn: 0.3417212\ttotal: 1.9s\tremaining: 28.2s\n",
      "63:\tlearn: 0.3410997\ttotal: 1.93s\tremaining: 28.2s\n",
      "64:\tlearn: 0.3405760\ttotal: 1.97s\tremaining: 28.3s\n",
      "65:\tlearn: 0.3399369\ttotal: 2s\tremaining: 28.4s\n",
      "66:\tlearn: 0.3391894\ttotal: 2.04s\tremaining: 28.5s\n",
      "67:\tlearn: 0.3387734\ttotal: 2.08s\tremaining: 28.4s\n",
      "68:\tlearn: 0.3383671\ttotal: 2.1s\tremaining: 28.3s\n",
      "69:\tlearn: 0.3379997\ttotal: 2.13s\tremaining: 28.3s\n",
      "70:\tlearn: 0.3376055\ttotal: 2.22s\tremaining: 29s\n",
      "71:\tlearn: 0.3372359\ttotal: 2.26s\tremaining: 29.1s\n",
      "72:\tlearn: 0.3369157\ttotal: 2.27s\tremaining: 28.9s\n",
      "73:\tlearn: 0.3364454\ttotal: 2.31s\tremaining: 28.9s\n",
      "74:\tlearn: 0.3360313\ttotal: 2.34s\tremaining: 28.9s\n",
      "75:\tlearn: 0.3357188\ttotal: 2.37s\tremaining: 28.9s\n",
      "76:\tlearn: 0.3353528\ttotal: 2.4s\tremaining: 28.8s\n",
      "77:\tlearn: 0.3348700\ttotal: 2.47s\tremaining: 29.2s\n",
      "78:\tlearn: 0.3346023\ttotal: 2.48s\tremaining: 28.9s\n",
      "79:\tlearn: 0.3341206\ttotal: 2.52s\tremaining: 29s\n",
      "80:\tlearn: 0.3337836\ttotal: 2.55s\tremaining: 28.9s\n",
      "81:\tlearn: 0.3334826\ttotal: 2.58s\tremaining: 28.9s\n",
      "82:\tlearn: 0.3330626\ttotal: 2.6s\tremaining: 28.7s\n",
      "83:\tlearn: 0.3326324\ttotal: 2.65s\tremaining: 28.9s\n",
      "84:\tlearn: 0.3323890\ttotal: 2.69s\tremaining: 28.9s\n",
      "85:\tlearn: 0.3320940\ttotal: 2.73s\tremaining: 29.1s\n",
      "86:\tlearn: 0.3318238\ttotal: 2.78s\tremaining: 29.2s\n",
      "87:\tlearn: 0.3315773\ttotal: 2.85s\tremaining: 29.5s\n",
      "88:\tlearn: 0.3311860\ttotal: 2.89s\tremaining: 29.6s\n",
      "89:\tlearn: 0.3310036\ttotal: 2.92s\tremaining: 29.5s\n",
      "90:\tlearn: 0.3308048\ttotal: 2.94s\tremaining: 29.3s\n",
      "91:\tlearn: 0.3306043\ttotal: 2.99s\tremaining: 29.5s\n",
      "92:\tlearn: 0.3302972\ttotal: 3.07s\tremaining: 30s\n",
      "93:\tlearn: 0.3300704\ttotal: 3.12s\tremaining: 30s\n",
      "94:\tlearn: 0.3298424\ttotal: 3.14s\tremaining: 29.9s\n",
      "95:\tlearn: 0.3296661\ttotal: 3.19s\tremaining: 30s\n",
      "96:\tlearn: 0.3293700\ttotal: 3.27s\tremaining: 30.4s\n",
      "97:\tlearn: 0.3290497\ttotal: 3.3s\tremaining: 30.3s\n",
      "98:\tlearn: 0.3286608\ttotal: 3.31s\tremaining: 30.2s\n",
      "99:\tlearn: 0.3284362\ttotal: 3.33s\tremaining: 30s\n",
      "100:\tlearn: 0.3282184\ttotal: 3.35s\tremaining: 29.8s\n",
      "101:\tlearn: 0.3280441\ttotal: 3.4s\tremaining: 30s\n",
      "102:\tlearn: 0.3278020\ttotal: 3.44s\tremaining: 29.9s\n",
      "103:\tlearn: 0.3276026\ttotal: 3.46s\tremaining: 29.8s\n",
      "104:\tlearn: 0.3272950\ttotal: 3.5s\tremaining: 29.8s\n",
      "105:\tlearn: 0.3271213\ttotal: 3.52s\tremaining: 29.7s\n",
      "106:\tlearn: 0.3269629\ttotal: 3.54s\tremaining: 29.6s\n",
      "107:\tlearn: 0.3267572\ttotal: 3.56s\tremaining: 29.4s\n",
      "108:\tlearn: 0.3265901\ttotal: 3.6s\tremaining: 29.4s\n",
      "109:\tlearn: 0.3264039\ttotal: 3.66s\tremaining: 29.6s\n",
      "110:\tlearn: 0.3261707\ttotal: 3.69s\tremaining: 29.6s\n",
      "111:\tlearn: 0.3259070\ttotal: 3.72s\tremaining: 29.5s\n",
      "112:\tlearn: 0.3256407\ttotal: 3.76s\tremaining: 29.5s\n",
      "113:\tlearn: 0.3254731\ttotal: 3.81s\tremaining: 29.7s\n",
      "114:\tlearn: 0.3253043\ttotal: 3.84s\tremaining: 29.5s\n",
      "115:\tlearn: 0.3251509\ttotal: 3.88s\tremaining: 29.5s\n",
      "116:\tlearn: 0.3249952\ttotal: 3.93s\tremaining: 29.7s\n",
      "117:\tlearn: 0.3247027\ttotal: 3.96s\tremaining: 29.6s\n",
      "118:\tlearn: 0.3244191\ttotal: 3.99s\tremaining: 29.5s\n",
      "119:\tlearn: 0.3242349\ttotal: 4.01s\tremaining: 29.4s\n",
      "120:\tlearn: 0.3241300\ttotal: 4.02s\tremaining: 29.2s\n",
      "121:\tlearn: 0.3239982\ttotal: 4.05s\tremaining: 29.2s\n",
      "122:\tlearn: 0.3238967\ttotal: 4.08s\tremaining: 29.1s\n",
      "123:\tlearn: 0.3238035\ttotal: 4.09s\tremaining: 28.9s\n",
      "124:\tlearn: 0.3236233\ttotal: 4.13s\tremaining: 28.9s\n",
      "125:\tlearn: 0.3234160\ttotal: 4.17s\tremaining: 28.9s\n",
      "126:\tlearn: 0.3232092\ttotal: 4.19s\tremaining: 28.8s\n",
      "127:\tlearn: 0.3230822\ttotal: 4.21s\tremaining: 28.7s\n",
      "128:\tlearn: 0.3229182\ttotal: 4.24s\tremaining: 28.6s\n",
      "129:\tlearn: 0.3226830\ttotal: 4.25s\tremaining: 28.5s\n",
      "130:\tlearn: 0.3224487\ttotal: 4.27s\tremaining: 28.4s\n",
      "131:\tlearn: 0.3223391\ttotal: 4.3s\tremaining: 28.3s\n",
      "132:\tlearn: 0.3222533\ttotal: 4.31s\tremaining: 28.1s\n",
      "133:\tlearn: 0.3221464\ttotal: 4.33s\tremaining: 28s\n",
      "134:\tlearn: 0.3220072\ttotal: 4.34s\tremaining: 27.8s\n",
      "135:\tlearn: 0.3218201\ttotal: 4.35s\tremaining: 27.6s\n",
      "136:\tlearn: 0.3216190\ttotal: 4.41s\tremaining: 27.8s\n",
      "137:\tlearn: 0.3213713\ttotal: 4.43s\tremaining: 27.6s\n",
      "138:\tlearn: 0.3211347\ttotal: 4.45s\tremaining: 27.5s\n",
      "139:\tlearn: 0.3209747\ttotal: 4.46s\tremaining: 27.4s\n",
      "140:\tlearn: 0.3208221\ttotal: 4.48s\tremaining: 27.3s\n",
      "141:\tlearn: 0.3206556\ttotal: 4.49s\tremaining: 27.1s\n",
      "142:\tlearn: 0.3205258\ttotal: 4.52s\tremaining: 27.1s\n",
      "143:\tlearn: 0.3204103\ttotal: 4.53s\tremaining: 26.9s\n",
      "144:\tlearn: 0.3202759\ttotal: 4.55s\tremaining: 26.8s\n",
      "145:\tlearn: 0.3201301\ttotal: 4.58s\tremaining: 26.8s\n",
      "146:\tlearn: 0.3199745\ttotal: 4.59s\tremaining: 26.7s\n",
      "147:\tlearn: 0.3198659\ttotal: 4.62s\tremaining: 26.6s\n",
      "148:\tlearn: 0.3196838\ttotal: 4.65s\tremaining: 26.6s\n",
      "149:\tlearn: 0.3195126\ttotal: 4.66s\tremaining: 26.4s\n",
      "150:\tlearn: 0.3193288\ttotal: 4.67s\tremaining: 26.3s\n",
      "151:\tlearn: 0.3191817\ttotal: 4.69s\tremaining: 26.1s\n",
      "152:\tlearn: 0.3190359\ttotal: 4.7s\tremaining: 26s\n",
      "153:\tlearn: 0.3188468\ttotal: 4.71s\tremaining: 25.9s\n",
      "154:\tlearn: 0.3186648\ttotal: 4.72s\tremaining: 25.7s\n",
      "155:\tlearn: 0.3185276\ttotal: 4.73s\tremaining: 25.6s\n",
      "156:\tlearn: 0.3183414\ttotal: 4.76s\tremaining: 25.6s\n",
      "157:\tlearn: 0.3182238\ttotal: 4.77s\tremaining: 25.4s\n",
      "158:\tlearn: 0.3181407\ttotal: 4.79s\tremaining: 25.3s\n",
      "159:\tlearn: 0.3179921\ttotal: 4.8s\tremaining: 25.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160:\tlearn: 0.3178744\ttotal: 4.82s\tremaining: 25.1s\n",
      "161:\tlearn: 0.3177432\ttotal: 4.83s\tremaining: 25s\n",
      "162:\tlearn: 0.3175754\ttotal: 4.85s\tremaining: 24.9s\n",
      "163:\tlearn: 0.3174715\ttotal: 4.87s\tremaining: 24.8s\n",
      "164:\tlearn: 0.3173419\ttotal: 4.88s\tremaining: 24.7s\n",
      "165:\tlearn: 0.3172402\ttotal: 4.89s\tremaining: 24.6s\n",
      "166:\tlearn: 0.3171088\ttotal: 4.91s\tremaining: 24.5s\n",
      "167:\tlearn: 0.3169291\ttotal: 4.93s\tremaining: 24.4s\n",
      "168:\tlearn: 0.3167286\ttotal: 4.99s\tremaining: 24.5s\n",
      "169:\tlearn: 0.3166297\ttotal: 5.01s\tremaining: 24.5s\n",
      "170:\tlearn: 0.3165688\ttotal: 5.02s\tremaining: 24.4s\n",
      "171:\tlearn: 0.3164540\ttotal: 5.04s\tremaining: 24.3s\n",
      "172:\tlearn: 0.3163252\ttotal: 5.05s\tremaining: 24.1s\n",
      "173:\tlearn: 0.3162186\ttotal: 5.07s\tremaining: 24.1s\n",
      "174:\tlearn: 0.3160959\ttotal: 5.08s\tremaining: 24s\n",
      "175:\tlearn: 0.3159868\ttotal: 5.12s\tremaining: 24s\n",
      "176:\tlearn: 0.3157836\ttotal: 5.14s\tremaining: 23.9s\n",
      "177:\tlearn: 0.3157058\ttotal: 5.15s\tremaining: 23.8s\n",
      "178:\tlearn: 0.3156219\ttotal: 5.17s\tremaining: 23.7s\n",
      "179:\tlearn: 0.3155683\ttotal: 5.18s\tremaining: 23.6s\n",
      "180:\tlearn: 0.3153738\ttotal: 5.2s\tremaining: 23.5s\n",
      "181:\tlearn: 0.3152305\ttotal: 5.24s\tremaining: 23.6s\n",
      "182:\tlearn: 0.3151612\ttotal: 5.25s\tremaining: 23.5s\n",
      "183:\tlearn: 0.3150073\ttotal: 5.27s\tremaining: 23.4s\n",
      "184:\tlearn: 0.3148012\ttotal: 5.28s\tremaining: 23.3s\n",
      "185:\tlearn: 0.3145441\ttotal: 5.29s\tremaining: 23.2s\n",
      "186:\tlearn: 0.3144845\ttotal: 5.31s\tremaining: 23.1s\n",
      "187:\tlearn: 0.3143537\ttotal: 5.33s\tremaining: 23s\n",
      "188:\tlearn: 0.3142637\ttotal: 5.36s\tremaining: 23s\n",
      "189:\tlearn: 0.3141388\ttotal: 5.38s\tremaining: 22.9s\n",
      "190:\tlearn: 0.3139800\ttotal: 5.4s\tremaining: 22.9s\n",
      "191:\tlearn: 0.3138636\ttotal: 5.41s\tremaining: 22.8s\n",
      "192:\tlearn: 0.3137825\ttotal: 5.42s\tremaining: 22.7s\n",
      "193:\tlearn: 0.3137150\ttotal: 5.46s\tremaining: 22.7s\n",
      "194:\tlearn: 0.3136159\ttotal: 5.47s\tremaining: 22.6s\n",
      "195:\tlearn: 0.3134625\ttotal: 5.49s\tremaining: 22.5s\n",
      "196:\tlearn: 0.3133581\ttotal: 5.51s\tremaining: 22.5s\n",
      "197:\tlearn: 0.3132182\ttotal: 5.56s\tremaining: 22.5s\n",
      "198:\tlearn: 0.3131399\ttotal: 5.58s\tremaining: 22.5s\n",
      "199:\tlearn: 0.3130068\ttotal: 5.6s\tremaining: 22.4s\n",
      "200:\tlearn: 0.3129416\ttotal: 5.63s\tremaining: 22.4s\n",
      "201:\tlearn: 0.3128780\ttotal: 5.66s\tremaining: 22.4s\n",
      "202:\tlearn: 0.3126884\ttotal: 5.72s\tremaining: 22.4s\n",
      "203:\tlearn: 0.3125727\ttotal: 5.75s\tremaining: 22.4s\n",
      "204:\tlearn: 0.3124737\ttotal: 5.77s\tremaining: 22.4s\n",
      "205:\tlearn: 0.3123645\ttotal: 5.79s\tremaining: 22.3s\n",
      "206:\tlearn: 0.3122366\ttotal: 5.83s\tremaining: 22.3s\n",
      "207:\tlearn: 0.3121178\ttotal: 5.84s\tremaining: 22.2s\n",
      "208:\tlearn: 0.3119900\ttotal: 5.85s\tremaining: 22.2s\n",
      "209:\tlearn: 0.3118625\ttotal: 5.88s\tremaining: 22.1s\n",
      "210:\tlearn: 0.3117713\ttotal: 5.9s\tremaining: 22.1s\n",
      "211:\tlearn: 0.3116557\ttotal: 5.93s\tremaining: 22s\n",
      "212:\tlearn: 0.3115145\ttotal: 5.96s\tremaining: 22s\n",
      "213:\tlearn: 0.3113818\ttotal: 5.97s\tremaining: 21.9s\n",
      "214:\tlearn: 0.3113038\ttotal: 5.98s\tremaining: 21.8s\n",
      "215:\tlearn: 0.3111708\ttotal: 5.99s\tremaining: 21.8s\n",
      "216:\tlearn: 0.3110207\ttotal: 6.01s\tremaining: 21.7s\n",
      "217:\tlearn: 0.3109655\ttotal: 6.02s\tremaining: 21.6s\n",
      "218:\tlearn: 0.3107779\ttotal: 6.03s\tremaining: 21.5s\n",
      "219:\tlearn: 0.3106186\ttotal: 6.04s\tremaining: 21.4s\n",
      "220:\tlearn: 0.3104859\ttotal: 6.07s\tremaining: 21.4s\n",
      "221:\tlearn: 0.3104265\ttotal: 6.09s\tremaining: 21.4s\n",
      "222:\tlearn: 0.3102622\ttotal: 6.12s\tremaining: 21.3s\n",
      "223:\tlearn: 0.3102354\ttotal: 6.14s\tremaining: 21.3s\n",
      "224:\tlearn: 0.3101103\ttotal: 6.16s\tremaining: 21.2s\n",
      "225:\tlearn: 0.3100219\ttotal: 6.18s\tremaining: 21.2s\n",
      "226:\tlearn: 0.3098760\ttotal: 6.2s\tremaining: 21.1s\n",
      "227:\tlearn: 0.3098006\ttotal: 6.24s\tremaining: 21.1s\n",
      "228:\tlearn: 0.3097047\ttotal: 6.25s\tremaining: 21s\n",
      "229:\tlearn: 0.3095938\ttotal: 6.26s\tremaining: 21s\n",
      "230:\tlearn: 0.3094282\ttotal: 6.27s\tremaining: 20.9s\n",
      "231:\tlearn: 0.3092733\ttotal: 6.31s\tremaining: 20.9s\n",
      "232:\tlearn: 0.3092139\ttotal: 6.32s\tremaining: 20.8s\n",
      "233:\tlearn: 0.3090237\ttotal: 6.35s\tremaining: 20.8s\n",
      "234:\tlearn: 0.3088893\ttotal: 6.37s\tremaining: 20.7s\n",
      "235:\tlearn: 0.3088115\ttotal: 6.39s\tremaining: 20.7s\n",
      "236:\tlearn: 0.3086753\ttotal: 6.42s\tremaining: 20.7s\n",
      "237:\tlearn: 0.3085867\ttotal: 6.44s\tremaining: 20.6s\n",
      "238:\tlearn: 0.3085221\ttotal: 6.45s\tremaining: 20.6s\n",
      "239:\tlearn: 0.3084092\ttotal: 6.47s\tremaining: 20.5s\n",
      "240:\tlearn: 0.3082804\ttotal: 6.48s\tremaining: 20.4s\n",
      "241:\tlearn: 0.3081545\ttotal: 6.5s\tremaining: 20.3s\n",
      "242:\tlearn: 0.3080089\ttotal: 6.53s\tremaining: 20.3s\n",
      "243:\tlearn: 0.3079010\ttotal: 6.55s\tremaining: 20.3s\n",
      "244:\tlearn: 0.3077507\ttotal: 6.57s\tremaining: 20.2s\n",
      "245:\tlearn: 0.3076656\ttotal: 6.58s\tremaining: 20.2s\n",
      "246:\tlearn: 0.3074605\ttotal: 6.6s\tremaining: 20.1s\n",
      "247:\tlearn: 0.3072993\ttotal: 6.61s\tremaining: 20.1s\n",
      "248:\tlearn: 0.3070996\ttotal: 6.64s\tremaining: 20s\n",
      "249:\tlearn: 0.3070029\ttotal: 6.66s\tremaining: 20s\n",
      "250:\tlearn: 0.3069289\ttotal: 6.68s\tremaining: 19.9s\n",
      "251:\tlearn: 0.3067466\ttotal: 6.7s\tremaining: 19.9s\n",
      "252:\tlearn: 0.3067005\ttotal: 6.71s\tremaining: 19.8s\n",
      "253:\tlearn: 0.3065141\ttotal: 6.75s\tremaining: 19.8s\n",
      "254:\tlearn: 0.3063339\ttotal: 6.77s\tremaining: 19.8s\n",
      "255:\tlearn: 0.3062833\ttotal: 6.78s\tremaining: 19.7s\n",
      "256:\tlearn: 0.3062321\ttotal: 6.79s\tremaining: 19.6s\n",
      "257:\tlearn: 0.3061777\ttotal: 6.8s\tremaining: 19.6s\n",
      "258:\tlearn: 0.3061263\ttotal: 6.82s\tremaining: 19.5s\n",
      "259:\tlearn: 0.3059219\ttotal: 6.84s\tremaining: 19.5s\n",
      "260:\tlearn: 0.3059024\ttotal: 6.86s\tremaining: 19.4s\n",
      "261:\tlearn: 0.3057546\ttotal: 6.87s\tremaining: 19.3s\n",
      "262:\tlearn: 0.3055873\ttotal: 6.88s\tremaining: 19.3s\n",
      "263:\tlearn: 0.3054920\ttotal: 6.9s\tremaining: 19.2s\n",
      "264:\tlearn: 0.3053935\ttotal: 6.91s\tremaining: 19.2s\n",
      "265:\tlearn: 0.3052911\ttotal: 6.96s\tremaining: 19.2s\n",
      "266:\tlearn: 0.3051849\ttotal: 6.99s\tremaining: 19.2s\n",
      "267:\tlearn: 0.3050550\ttotal: 7.01s\tremaining: 19.1s\n",
      "268:\tlearn: 0.3049091\ttotal: 7.02s\tremaining: 19.1s\n",
      "269:\tlearn: 0.3047622\ttotal: 7.04s\tremaining: 19s\n",
      "270:\tlearn: 0.3045571\ttotal: 7.07s\tremaining: 19s\n",
      "271:\tlearn: 0.3043658\ttotal: 7.09s\tremaining: 19s\n",
      "272:\tlearn: 0.3042814\ttotal: 7.12s\tremaining: 19s\n",
      "273:\tlearn: 0.3040690\ttotal: 7.16s\tremaining: 19s\n",
      "274:\tlearn: 0.3039135\ttotal: 7.21s\tremaining: 19s\n",
      "275:\tlearn: 0.3037585\ttotal: 7.25s\tremaining: 19s\n",
      "276:\tlearn: 0.3036000\ttotal: 7.27s\tremaining: 19s\n",
      "277:\tlearn: 0.3034547\ttotal: 7.3s\tremaining: 19s\n",
      "278:\tlearn: 0.3033996\ttotal: 7.32s\tremaining: 18.9s\n",
      "279:\tlearn: 0.3032133\ttotal: 7.34s\tremaining: 18.9s\n",
      "280:\tlearn: 0.3030256\ttotal: 7.38s\tremaining: 18.9s\n",
      "281:\tlearn: 0.3028880\ttotal: 7.4s\tremaining: 18.8s\n",
      "282:\tlearn: 0.3027301\ttotal: 7.43s\tremaining: 18.8s\n",
      "283:\tlearn: 0.3026559\ttotal: 7.45s\tremaining: 18.8s\n",
      "284:\tlearn: 0.3025954\ttotal: 7.47s\tremaining: 18.7s\n",
      "285:\tlearn: 0.3025249\ttotal: 7.49s\tremaining: 18.7s\n",
      "286:\tlearn: 0.3024620\ttotal: 7.51s\tremaining: 18.7s\n",
      "287:\tlearn: 0.3023371\ttotal: 7.53s\tremaining: 18.6s\n",
      "288:\tlearn: 0.3021545\ttotal: 7.54s\tremaining: 18.6s\n",
      "289:\tlearn: 0.3020612\ttotal: 7.56s\tremaining: 18.5s\n",
      "290:\tlearn: 0.3019696\ttotal: 7.57s\tremaining: 18.5s\n",
      "291:\tlearn: 0.3017871\ttotal: 7.59s\tremaining: 18.4s\n",
      "292:\tlearn: 0.3016805\ttotal: 7.61s\tremaining: 18.4s\n",
      "293:\tlearn: 0.3016116\ttotal: 7.62s\tremaining: 18.3s\n",
      "294:\tlearn: 0.3014390\ttotal: 7.64s\tremaining: 18.3s\n",
      "295:\tlearn: 0.3013433\ttotal: 7.66s\tremaining: 18.2s\n",
      "296:\tlearn: 0.3012340\ttotal: 7.67s\tremaining: 18.2s\n",
      "297:\tlearn: 0.3011724\ttotal: 7.68s\tremaining: 18.1s\n",
      "298:\tlearn: 0.3010660\ttotal: 7.7s\tremaining: 18s\n",
      "299:\tlearn: 0.3009768\ttotal: 7.71s\tremaining: 18s\n",
      "300:\tlearn: 0.3008880\ttotal: 7.72s\tremaining: 17.9s\n",
      "301:\tlearn: 0.3007439\ttotal: 7.73s\tremaining: 17.9s\n",
      "302:\tlearn: 0.3005654\ttotal: 7.74s\tremaining: 17.8s\n",
      "303:\tlearn: 0.3004532\ttotal: 7.75s\tremaining: 17.8s\n",
      "304:\tlearn: 0.3003439\ttotal: 7.77s\tremaining: 17.7s\n",
      "305:\tlearn: 0.3001766\ttotal: 7.79s\tremaining: 17.7s\n",
      "306:\tlearn: 0.3000091\ttotal: 7.84s\tremaining: 17.7s\n",
      "307:\tlearn: 0.2998778\ttotal: 7.86s\tremaining: 17.7s\n",
      "308:\tlearn: 0.2998454\ttotal: 7.88s\tremaining: 17.6s\n",
      "309:\tlearn: 0.2996697\ttotal: 7.9s\tremaining: 17.6s\n",
      "310:\tlearn: 0.2995020\ttotal: 7.92s\tremaining: 17.6s\n",
      "311:\tlearn: 0.2993997\ttotal: 7.94s\tremaining: 17.5s\n",
      "312:\tlearn: 0.2992736\ttotal: 7.96s\tremaining: 17.5s\n",
      "313:\tlearn: 0.2990989\ttotal: 7.97s\tremaining: 17.4s\n",
      "314:\tlearn: 0.2989456\ttotal: 7.99s\tremaining: 17.4s\n",
      "315:\tlearn: 0.2988353\ttotal: 8.01s\tremaining: 17.3s\n",
      "316:\tlearn: 0.2987305\ttotal: 8.02s\tremaining: 17.3s\n",
      "317:\tlearn: 0.2985836\ttotal: 8.05s\tremaining: 17.3s\n",
      "318:\tlearn: 0.2983933\ttotal: 8.07s\tremaining: 17.2s\n",
      "319:\tlearn: 0.2982371\ttotal: 8.09s\tremaining: 17.2s\n",
      "320:\tlearn: 0.2980054\ttotal: 8.11s\tremaining: 17.1s\n",
      "321:\tlearn: 0.2978024\ttotal: 8.12s\tremaining: 17.1s\n",
      "322:\tlearn: 0.2976553\ttotal: 8.14s\tremaining: 17.1s\n",
      "323:\tlearn: 0.2975255\ttotal: 8.15s\tremaining: 17s\n",
      "324:\tlearn: 0.2974040\ttotal: 8.18s\tremaining: 17s\n",
      "325:\tlearn: 0.2973144\ttotal: 8.21s\tremaining: 17s\n",
      "326:\tlearn: 0.2971186\ttotal: 8.24s\tremaining: 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327:\tlearn: 0.2969859\ttotal: 8.26s\tremaining: 16.9s\n",
      "328:\tlearn: 0.2968675\ttotal: 8.28s\tremaining: 16.9s\n",
      "329:\tlearn: 0.2967228\ttotal: 8.29s\tremaining: 16.8s\n",
      "330:\tlearn: 0.2966201\ttotal: 8.31s\tremaining: 16.8s\n",
      "331:\tlearn: 0.2965023\ttotal: 8.33s\tremaining: 16.8s\n",
      "332:\tlearn: 0.2963611\ttotal: 8.36s\tremaining: 16.7s\n",
      "333:\tlearn: 0.2962283\ttotal: 8.38s\tremaining: 16.7s\n",
      "334:\tlearn: 0.2960758\ttotal: 8.39s\tremaining: 16.7s\n",
      "335:\tlearn: 0.2958592\ttotal: 8.41s\tremaining: 16.6s\n",
      "336:\tlearn: 0.2957005\ttotal: 8.42s\tremaining: 16.6s\n",
      "337:\tlearn: 0.2955505\ttotal: 8.44s\tremaining: 16.5s\n",
      "338:\tlearn: 0.2953345\ttotal: 8.46s\tremaining: 16.5s\n",
      "339:\tlearn: 0.2952970\ttotal: 8.47s\tremaining: 16.4s\n",
      "340:\tlearn: 0.2952203\ttotal: 8.49s\tremaining: 16.4s\n",
      "341:\tlearn: 0.2951061\ttotal: 8.51s\tremaining: 16.4s\n",
      "342:\tlearn: 0.2949749\ttotal: 8.53s\tremaining: 16.3s\n",
      "343:\tlearn: 0.2948591\ttotal: 8.54s\tremaining: 16.3s\n",
      "344:\tlearn: 0.2947869\ttotal: 8.56s\tremaining: 16.2s\n",
      "345:\tlearn: 0.2946728\ttotal: 8.57s\tremaining: 16.2s\n",
      "346:\tlearn: 0.2945136\ttotal: 8.59s\tremaining: 16.2s\n",
      "347:\tlearn: 0.2943293\ttotal: 8.62s\tremaining: 16.1s\n",
      "348:\tlearn: 0.2941474\ttotal: 8.64s\tremaining: 16.1s\n",
      "349:\tlearn: 0.2940057\ttotal: 8.68s\tremaining: 16.1s\n",
      "350:\tlearn: 0.2938443\ttotal: 8.71s\tremaining: 16.1s\n",
      "351:\tlearn: 0.2937772\ttotal: 8.73s\tremaining: 16.1s\n",
      "352:\tlearn: 0.2936492\ttotal: 8.74s\tremaining: 16s\n",
      "353:\tlearn: 0.2935950\ttotal: 8.75s\tremaining: 16s\n",
      "354:\tlearn: 0.2934947\ttotal: 8.76s\tremaining: 15.9s\n",
      "355:\tlearn: 0.2933553\ttotal: 8.77s\tremaining: 15.9s\n",
      "356:\tlearn: 0.2932135\ttotal: 8.79s\tremaining: 15.8s\n",
      "357:\tlearn: 0.2931306\ttotal: 8.8s\tremaining: 15.8s\n",
      "358:\tlearn: 0.2930528\ttotal: 8.81s\tremaining: 15.7s\n",
      "359:\tlearn: 0.2929551\ttotal: 8.83s\tremaining: 15.7s\n",
      "360:\tlearn: 0.2928624\ttotal: 8.85s\tremaining: 15.7s\n",
      "361:\tlearn: 0.2927021\ttotal: 8.87s\tremaining: 15.6s\n",
      "362:\tlearn: 0.2925747\ttotal: 8.9s\tremaining: 15.6s\n",
      "363:\tlearn: 0.2924858\ttotal: 8.91s\tremaining: 15.6s\n",
      "364:\tlearn: 0.2923821\ttotal: 8.93s\tremaining: 15.5s\n",
      "365:\tlearn: 0.2922244\ttotal: 8.94s\tremaining: 15.5s\n",
      "366:\tlearn: 0.2920608\ttotal: 8.95s\tremaining: 15.4s\n",
      "367:\tlearn: 0.2919118\ttotal: 8.96s\tremaining: 15.4s\n",
      "368:\tlearn: 0.2917856\ttotal: 8.98s\tremaining: 15.3s\n",
      "369:\tlearn: 0.2917066\ttotal: 8.99s\tremaining: 15.3s\n",
      "370:\tlearn: 0.2915390\ttotal: 9s\tremaining: 15.3s\n",
      "371:\tlearn: 0.2914193\ttotal: 9.02s\tremaining: 15.2s\n",
      "372:\tlearn: 0.2913196\ttotal: 9.05s\tremaining: 15.2s\n",
      "373:\tlearn: 0.2911329\ttotal: 9.07s\tremaining: 15.2s\n",
      "374:\tlearn: 0.2909724\ttotal: 9.08s\tremaining: 15.1s\n",
      "375:\tlearn: 0.2907977\ttotal: 9.1s\tremaining: 15.1s\n",
      "376:\tlearn: 0.2907314\ttotal: 9.11s\tremaining: 15.1s\n",
      "377:\tlearn: 0.2904599\ttotal: 9.13s\tremaining: 15s\n",
      "378:\tlearn: 0.2903025\ttotal: 9.14s\tremaining: 15s\n",
      "379:\tlearn: 0.2901236\ttotal: 9.15s\tremaining: 14.9s\n",
      "380:\tlearn: 0.2899045\ttotal: 9.16s\tremaining: 14.9s\n",
      "381:\tlearn: 0.2897344\ttotal: 9.18s\tremaining: 14.8s\n",
      "382:\tlearn: 0.2895696\ttotal: 9.22s\tremaining: 14.9s\n",
      "383:\tlearn: 0.2894180\ttotal: 9.24s\tremaining: 14.8s\n",
      "384:\tlearn: 0.2891942\ttotal: 9.26s\tremaining: 14.8s\n",
      "385:\tlearn: 0.2891239\ttotal: 9.27s\tremaining: 14.7s\n",
      "386:\tlearn: 0.2890406\ttotal: 9.29s\tremaining: 14.7s\n",
      "387:\tlearn: 0.2888878\ttotal: 9.3s\tremaining: 14.7s\n",
      "388:\tlearn: 0.2887807\ttotal: 9.32s\tremaining: 14.6s\n",
      "389:\tlearn: 0.2886986\ttotal: 9.33s\tremaining: 14.6s\n",
      "390:\tlearn: 0.2885431\ttotal: 9.35s\tremaining: 14.6s\n",
      "391:\tlearn: 0.2883641\ttotal: 9.36s\tremaining: 14.5s\n",
      "392:\tlearn: 0.2882280\ttotal: 9.37s\tremaining: 14.5s\n",
      "393:\tlearn: 0.2880115\ttotal: 9.38s\tremaining: 14.4s\n",
      "394:\tlearn: 0.2878633\ttotal: 9.4s\tremaining: 14.4s\n",
      "395:\tlearn: 0.2877038\ttotal: 9.42s\tremaining: 14.4s\n",
      "396:\tlearn: 0.2874866\ttotal: 9.43s\tremaining: 14.3s\n",
      "397:\tlearn: 0.2874050\ttotal: 9.44s\tremaining: 14.3s\n",
      "398:\tlearn: 0.2873043\ttotal: 9.45s\tremaining: 14.2s\n",
      "399:\tlearn: 0.2871281\ttotal: 9.47s\tremaining: 14.2s\n",
      "400:\tlearn: 0.2869786\ttotal: 9.48s\tremaining: 14.2s\n",
      "401:\tlearn: 0.2868650\ttotal: 9.5s\tremaining: 14.1s\n",
      "402:\tlearn: 0.2866582\ttotal: 9.51s\tremaining: 14.1s\n",
      "403:\tlearn: 0.2864399\ttotal: 9.53s\tremaining: 14.1s\n",
      "404:\tlearn: 0.2863361\ttotal: 9.54s\tremaining: 14s\n",
      "405:\tlearn: 0.2861668\ttotal: 9.55s\tremaining: 14s\n",
      "406:\tlearn: 0.2860302\ttotal: 9.56s\tremaining: 13.9s\n",
      "407:\tlearn: 0.2858421\ttotal: 9.57s\tremaining: 13.9s\n",
      "408:\tlearn: 0.2856271\ttotal: 9.59s\tremaining: 13.9s\n",
      "409:\tlearn: 0.2854896\ttotal: 9.61s\tremaining: 13.8s\n",
      "410:\tlearn: 0.2854015\ttotal: 9.62s\tremaining: 13.8s\n",
      "411:\tlearn: 0.2852290\ttotal: 9.63s\tremaining: 13.7s\n",
      "412:\tlearn: 0.2850385\ttotal: 9.64s\tremaining: 13.7s\n",
      "413:\tlearn: 0.2848714\ttotal: 9.66s\tremaining: 13.7s\n",
      "414:\tlearn: 0.2847686\ttotal: 9.67s\tremaining: 13.6s\n",
      "415:\tlearn: 0.2846369\ttotal: 9.68s\tremaining: 13.6s\n",
      "416:\tlearn: 0.2844964\ttotal: 9.7s\tremaining: 13.6s\n",
      "417:\tlearn: 0.2843439\ttotal: 9.73s\tremaining: 13.5s\n",
      "418:\tlearn: 0.2842031\ttotal: 9.74s\tremaining: 13.5s\n",
      "419:\tlearn: 0.2840628\ttotal: 9.75s\tremaining: 13.5s\n",
      "420:\tlearn: 0.2838836\ttotal: 9.76s\tremaining: 13.4s\n",
      "421:\tlearn: 0.2837468\ttotal: 9.78s\tremaining: 13.4s\n",
      "422:\tlearn: 0.2836093\ttotal: 9.79s\tremaining: 13.4s\n",
      "423:\tlearn: 0.2835368\ttotal: 9.81s\tremaining: 13.3s\n",
      "424:\tlearn: 0.2834236\ttotal: 9.82s\tremaining: 13.3s\n",
      "425:\tlearn: 0.2833193\ttotal: 9.84s\tremaining: 13.3s\n",
      "426:\tlearn: 0.2832636\ttotal: 9.85s\tremaining: 13.2s\n",
      "427:\tlearn: 0.2831280\ttotal: 9.86s\tremaining: 13.2s\n",
      "428:\tlearn: 0.2829919\ttotal: 9.87s\tremaining: 13.1s\n",
      "429:\tlearn: 0.2828354\ttotal: 9.9s\tremaining: 13.1s\n",
      "430:\tlearn: 0.2827042\ttotal: 9.92s\tremaining: 13.1s\n",
      "431:\tlearn: 0.2824859\ttotal: 9.93s\tremaining: 13.1s\n",
      "432:\tlearn: 0.2823277\ttotal: 9.95s\tremaining: 13s\n",
      "433:\tlearn: 0.2822432\ttotal: 9.97s\tremaining: 13s\n",
      "434:\tlearn: 0.2820953\ttotal: 9.98s\tremaining: 13s\n",
      "435:\tlearn: 0.2819335\ttotal: 9.99s\tremaining: 12.9s\n",
      "436:\tlearn: 0.2817704\ttotal: 10s\tremaining: 12.9s\n",
      "437:\tlearn: 0.2817013\ttotal: 10s\tremaining: 12.9s\n",
      "438:\tlearn: 0.2815584\ttotal: 10s\tremaining: 12.8s\n",
      "439:\tlearn: 0.2814591\ttotal: 10s\tremaining: 12.8s\n",
      "440:\tlearn: 0.2812864\ttotal: 10.1s\tremaining: 12.7s\n",
      "441:\tlearn: 0.2811247\ttotal: 10.1s\tremaining: 12.7s\n",
      "442:\tlearn: 0.2809729\ttotal: 10.1s\tremaining: 12.7s\n",
      "443:\tlearn: 0.2809013\ttotal: 10.1s\tremaining: 12.6s\n",
      "444:\tlearn: 0.2808433\ttotal: 10.1s\tremaining: 12.6s\n",
      "445:\tlearn: 0.2806920\ttotal: 10.1s\tremaining: 12.6s\n",
      "446:\tlearn: 0.2804554\ttotal: 10.1s\tremaining: 12.5s\n",
      "447:\tlearn: 0.2803741\ttotal: 10.2s\tremaining: 12.5s\n",
      "448:\tlearn: 0.2802764\ttotal: 10.2s\tremaining: 12.5s\n",
      "449:\tlearn: 0.2801941\ttotal: 10.2s\tremaining: 12.5s\n",
      "450:\tlearn: 0.2800469\ttotal: 10.2s\tremaining: 12.4s\n",
      "451:\tlearn: 0.2799403\ttotal: 10.2s\tremaining: 12.4s\n",
      "452:\tlearn: 0.2798232\ttotal: 10.2s\tremaining: 12.4s\n",
      "453:\tlearn: 0.2796578\ttotal: 10.2s\tremaining: 12.3s\n",
      "454:\tlearn: 0.2795430\ttotal: 10.3s\tremaining: 12.3s\n",
      "455:\tlearn: 0.2793831\ttotal: 10.3s\tremaining: 12.3s\n",
      "456:\tlearn: 0.2793034\ttotal: 10.3s\tremaining: 12.2s\n",
      "457:\tlearn: 0.2792130\ttotal: 10.3s\tremaining: 12.2s\n",
      "458:\tlearn: 0.2790222\ttotal: 10.3s\tremaining: 12.2s\n",
      "459:\tlearn: 0.2787912\ttotal: 10.3s\tremaining: 12.1s\n",
      "460:\tlearn: 0.2786555\ttotal: 10.4s\tremaining: 12.1s\n",
      "461:\tlearn: 0.2785148\ttotal: 10.4s\tremaining: 12.1s\n",
      "462:\tlearn: 0.2782834\ttotal: 10.4s\tremaining: 12s\n",
      "463:\tlearn: 0.2781705\ttotal: 10.4s\tremaining: 12s\n",
      "464:\tlearn: 0.2780995\ttotal: 10.4s\tremaining: 12s\n",
      "465:\tlearn: 0.2779994\ttotal: 10.4s\tremaining: 11.9s\n",
      "466:\tlearn: 0.2779037\ttotal: 10.4s\tremaining: 11.9s\n",
      "467:\tlearn: 0.2778363\ttotal: 10.4s\tremaining: 11.9s\n",
      "468:\tlearn: 0.2777731\ttotal: 10.4s\tremaining: 11.8s\n",
      "469:\tlearn: 0.2777305\ttotal: 10.5s\tremaining: 11.8s\n",
      "470:\tlearn: 0.2776598\ttotal: 10.5s\tremaining: 11.8s\n",
      "471:\tlearn: 0.2775625\ttotal: 10.5s\tremaining: 11.7s\n",
      "472:\tlearn: 0.2773635\ttotal: 10.5s\tremaining: 11.7s\n",
      "473:\tlearn: 0.2772562\ttotal: 10.5s\tremaining: 11.7s\n",
      "474:\tlearn: 0.2771547\ttotal: 10.6s\tremaining: 11.7s\n",
      "475:\tlearn: 0.2770026\ttotal: 10.6s\tremaining: 11.6s\n",
      "476:\tlearn: 0.2769484\ttotal: 10.6s\tremaining: 11.6s\n",
      "477:\tlearn: 0.2768664\ttotal: 10.6s\tremaining: 11.6s\n",
      "478:\tlearn: 0.2767929\ttotal: 10.6s\tremaining: 11.6s\n",
      "479:\tlearn: 0.2766699\ttotal: 10.6s\tremaining: 11.5s\n",
      "480:\tlearn: 0.2765801\ttotal: 10.7s\tremaining: 11.5s\n",
      "481:\tlearn: 0.2764288\ttotal: 10.7s\tremaining: 11.5s\n",
      "482:\tlearn: 0.2763048\ttotal: 10.7s\tremaining: 11.4s\n",
      "483:\tlearn: 0.2762048\ttotal: 10.7s\tremaining: 11.4s\n",
      "484:\tlearn: 0.2760857\ttotal: 10.7s\tremaining: 11.4s\n",
      "485:\tlearn: 0.2759439\ttotal: 10.8s\tremaining: 11.4s\n",
      "486:\tlearn: 0.2758489\ttotal: 10.8s\tremaining: 11.4s\n",
      "487:\tlearn: 0.2757242\ttotal: 10.8s\tremaining: 11.3s\n",
      "488:\tlearn: 0.2757071\ttotal: 10.8s\tremaining: 11.3s\n",
      "489:\tlearn: 0.2756431\ttotal: 10.8s\tremaining: 11.3s\n",
      "490:\tlearn: 0.2755649\ttotal: 10.8s\tremaining: 11.2s\n",
      "491:\tlearn: 0.2753713\ttotal: 10.8s\tremaining: 11.2s\n",
      "492:\tlearn: 0.2752613\ttotal: 10.9s\tremaining: 11.2s\n",
      "493:\tlearn: 0.2750780\ttotal: 10.9s\tremaining: 11.1s\n",
      "494:\tlearn: 0.2749545\ttotal: 10.9s\tremaining: 11.1s\n",
      "495:\tlearn: 0.2748417\ttotal: 10.9s\tremaining: 11.1s\n",
      "496:\tlearn: 0.2746936\ttotal: 10.9s\tremaining: 11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497:\tlearn: 0.2746038\ttotal: 10.9s\tremaining: 11s\n",
      "498:\tlearn: 0.2745295\ttotal: 10.9s\tremaining: 11s\n",
      "499:\tlearn: 0.2744089\ttotal: 11s\tremaining: 11s\n",
      "500:\tlearn: 0.2743046\ttotal: 11s\tremaining: 10.9s\n",
      "501:\tlearn: 0.2741787\ttotal: 11s\tremaining: 10.9s\n",
      "502:\tlearn: 0.2740413\ttotal: 11s\tremaining: 10.9s\n",
      "503:\tlearn: 0.2739526\ttotal: 11s\tremaining: 10.9s\n",
      "504:\tlearn: 0.2738464\ttotal: 11.1s\tremaining: 10.8s\n",
      "505:\tlearn: 0.2736685\ttotal: 11.1s\tremaining: 10.8s\n",
      "506:\tlearn: 0.2734707\ttotal: 11.1s\tremaining: 10.8s\n",
      "507:\tlearn: 0.2733089\ttotal: 11.1s\tremaining: 10.8s\n",
      "508:\tlearn: 0.2732200\ttotal: 11.1s\tremaining: 10.7s\n",
      "509:\tlearn: 0.2731168\ttotal: 11.2s\tremaining: 10.7s\n",
      "510:\tlearn: 0.2729851\ttotal: 11.2s\tremaining: 10.7s\n",
      "511:\tlearn: 0.2728475\ttotal: 11.2s\tremaining: 10.7s\n",
      "512:\tlearn: 0.2727632\ttotal: 11.2s\tremaining: 10.6s\n",
      "513:\tlearn: 0.2726177\ttotal: 11.2s\tremaining: 10.6s\n",
      "514:\tlearn: 0.2724980\ttotal: 11.2s\tremaining: 10.6s\n",
      "515:\tlearn: 0.2724587\ttotal: 11.3s\tremaining: 10.6s\n",
      "516:\tlearn: 0.2723876\ttotal: 11.3s\tremaining: 10.5s\n",
      "517:\tlearn: 0.2722027\ttotal: 11.3s\tremaining: 10.5s\n",
      "518:\tlearn: 0.2720457\ttotal: 11.3s\tremaining: 10.5s\n",
      "519:\tlearn: 0.2719286\ttotal: 11.3s\tremaining: 10.4s\n",
      "520:\tlearn: 0.2717693\ttotal: 11.3s\tremaining: 10.4s\n",
      "521:\tlearn: 0.2717359\ttotal: 11.3s\tremaining: 10.4s\n",
      "522:\tlearn: 0.2716479\ttotal: 11.3s\tremaining: 10.3s\n",
      "523:\tlearn: 0.2715202\ttotal: 11.4s\tremaining: 10.3s\n",
      "524:\tlearn: 0.2714525\ttotal: 11.4s\tremaining: 10.3s\n",
      "525:\tlearn: 0.2712874\ttotal: 11.4s\tremaining: 10.3s\n",
      "526:\tlearn: 0.2712056\ttotal: 11.4s\tremaining: 10.2s\n",
      "527:\tlearn: 0.2711598\ttotal: 11.4s\tremaining: 10.2s\n",
      "528:\tlearn: 0.2710237\ttotal: 11.4s\tremaining: 10.2s\n",
      "529:\tlearn: 0.2708856\ttotal: 11.4s\tremaining: 10.1s\n",
      "530:\tlearn: 0.2707745\ttotal: 11.5s\tremaining: 10.1s\n",
      "531:\tlearn: 0.2706147\ttotal: 11.5s\tremaining: 10.1s\n",
      "532:\tlearn: 0.2704448\ttotal: 11.5s\tremaining: 10.1s\n",
      "533:\tlearn: 0.2703158\ttotal: 11.5s\tremaining: 10s\n",
      "534:\tlearn: 0.2701487\ttotal: 11.5s\tremaining: 10s\n",
      "535:\tlearn: 0.2700335\ttotal: 11.5s\tremaining: 9.97s\n",
      "536:\tlearn: 0.2698741\ttotal: 11.5s\tremaining: 9.94s\n",
      "537:\tlearn: 0.2696899\ttotal: 11.6s\tremaining: 9.93s\n",
      "538:\tlearn: 0.2695498\ttotal: 11.6s\tremaining: 9.9s\n",
      "539:\tlearn: 0.2694438\ttotal: 11.6s\tremaining: 9.88s\n",
      "540:\tlearn: 0.2692959\ttotal: 11.6s\tremaining: 9.86s\n",
      "541:\tlearn: 0.2692450\ttotal: 11.6s\tremaining: 9.83s\n",
      "542:\tlearn: 0.2691110\ttotal: 11.6s\tremaining: 9.8s\n",
      "543:\tlearn: 0.2689297\ttotal: 11.7s\tremaining: 9.78s\n",
      "544:\tlearn: 0.2687922\ttotal: 11.7s\tremaining: 9.76s\n",
      "545:\tlearn: 0.2687360\ttotal: 11.7s\tremaining: 9.73s\n",
      "546:\tlearn: 0.2686736\ttotal: 11.7s\tremaining: 9.71s\n",
      "547:\tlearn: 0.2686034\ttotal: 11.7s\tremaining: 9.68s\n",
      "548:\tlearn: 0.2684002\ttotal: 11.8s\tremaining: 9.66s\n",
      "549:\tlearn: 0.2682741\ttotal: 11.8s\tremaining: 9.63s\n",
      "550:\tlearn: 0.2682352\ttotal: 11.8s\tremaining: 9.61s\n",
      "551:\tlearn: 0.2681189\ttotal: 11.8s\tremaining: 9.59s\n",
      "552:\tlearn: 0.2679819\ttotal: 11.8s\tremaining: 9.57s\n",
      "553:\tlearn: 0.2678482\ttotal: 11.8s\tremaining: 9.54s\n",
      "554:\tlearn: 0.2677463\ttotal: 11.9s\tremaining: 9.51s\n",
      "555:\tlearn: 0.2676625\ttotal: 11.9s\tremaining: 9.49s\n",
      "556:\tlearn: 0.2676165\ttotal: 11.9s\tremaining: 9.46s\n",
      "557:\tlearn: 0.2674657\ttotal: 11.9s\tremaining: 9.44s\n",
      "558:\tlearn: 0.2673928\ttotal: 11.9s\tremaining: 9.41s\n",
      "559:\tlearn: 0.2673354\ttotal: 11.9s\tremaining: 9.39s\n",
      "560:\tlearn: 0.2672349\ttotal: 12s\tremaining: 9.36s\n",
      "561:\tlearn: 0.2670393\ttotal: 12s\tremaining: 9.34s\n",
      "562:\tlearn: 0.2670079\ttotal: 12s\tremaining: 9.32s\n",
      "563:\tlearn: 0.2669421\ttotal: 12s\tremaining: 9.29s\n",
      "564:\tlearn: 0.2668208\ttotal: 12s\tremaining: 9.26s\n",
      "565:\tlearn: 0.2667449\ttotal: 12s\tremaining: 9.24s\n",
      "566:\tlearn: 0.2667101\ttotal: 12.1s\tremaining: 9.21s\n",
      "567:\tlearn: 0.2665570\ttotal: 12.1s\tremaining: 9.18s\n",
      "568:\tlearn: 0.2664586\ttotal: 12.1s\tremaining: 9.16s\n",
      "569:\tlearn: 0.2663731\ttotal: 12.1s\tremaining: 9.13s\n",
      "570:\tlearn: 0.2662478\ttotal: 12.1s\tremaining: 9.11s\n",
      "571:\tlearn: 0.2661948\ttotal: 12.2s\tremaining: 9.09s\n",
      "572:\tlearn: 0.2660180\ttotal: 12.2s\tremaining: 9.07s\n",
      "573:\tlearn: 0.2659492\ttotal: 12.2s\tremaining: 9.05s\n",
      "574:\tlearn: 0.2658193\ttotal: 12.2s\tremaining: 9.02s\n",
      "575:\tlearn: 0.2656729\ttotal: 12.2s\tremaining: 8.99s\n",
      "576:\tlearn: 0.2655650\ttotal: 12.2s\tremaining: 8.96s\n",
      "577:\tlearn: 0.2654030\ttotal: 12.2s\tremaining: 8.94s\n",
      "578:\tlearn: 0.2653499\ttotal: 12.3s\tremaining: 8.91s\n",
      "579:\tlearn: 0.2651661\ttotal: 12.3s\tremaining: 8.88s\n",
      "580:\tlearn: 0.2650901\ttotal: 12.3s\tremaining: 8.86s\n",
      "581:\tlearn: 0.2649249\ttotal: 12.3s\tremaining: 8.83s\n",
      "582:\tlearn: 0.2648109\ttotal: 12.3s\tremaining: 8.8s\n",
      "583:\tlearn: 0.2646836\ttotal: 12.3s\tremaining: 8.78s\n",
      "584:\tlearn: 0.2645506\ttotal: 12.3s\tremaining: 8.75s\n",
      "585:\tlearn: 0.2644136\ttotal: 12.4s\tremaining: 8.73s\n",
      "586:\tlearn: 0.2643055\ttotal: 12.4s\tremaining: 8.71s\n",
      "587:\tlearn: 0.2642532\ttotal: 12.4s\tremaining: 8.68s\n",
      "588:\tlearn: 0.2641478\ttotal: 12.4s\tremaining: 8.65s\n",
      "589:\tlearn: 0.2640164\ttotal: 12.4s\tremaining: 8.63s\n",
      "590:\tlearn: 0.2639286\ttotal: 12.4s\tremaining: 8.61s\n",
      "591:\tlearn: 0.2638483\ttotal: 12.5s\tremaining: 8.58s\n",
      "592:\tlearn: 0.2637936\ttotal: 12.5s\tremaining: 8.56s\n",
      "593:\tlearn: 0.2637179\ttotal: 12.5s\tremaining: 8.53s\n",
      "594:\tlearn: 0.2636114\ttotal: 12.5s\tremaining: 8.51s\n",
      "595:\tlearn: 0.2635480\ttotal: 12.5s\tremaining: 8.48s\n",
      "596:\tlearn: 0.2633779\ttotal: 12.5s\tremaining: 8.47s\n",
      "597:\tlearn: 0.2632799\ttotal: 12.6s\tremaining: 8.46s\n",
      "598:\tlearn: 0.2631150\ttotal: 12.6s\tremaining: 8.46s\n",
      "599:\tlearn: 0.2629899\ttotal: 12.7s\tremaining: 8.46s\n",
      "600:\tlearn: 0.2629554\ttotal: 12.7s\tremaining: 8.43s\n",
      "601:\tlearn: 0.2629307\ttotal: 12.7s\tremaining: 8.41s\n",
      "602:\tlearn: 0.2628289\ttotal: 12.8s\tremaining: 8.4s\n",
      "603:\tlearn: 0.2627423\ttotal: 12.8s\tremaining: 8.38s\n",
      "604:\tlearn: 0.2625790\ttotal: 12.8s\tremaining: 8.37s\n",
      "605:\tlearn: 0.2624513\ttotal: 12.9s\tremaining: 8.36s\n",
      "606:\tlearn: 0.2623141\ttotal: 12.9s\tremaining: 8.33s\n",
      "607:\tlearn: 0.2621394\ttotal: 12.9s\tremaining: 8.32s\n",
      "608:\tlearn: 0.2619532\ttotal: 12.9s\tremaining: 8.3s\n",
      "609:\tlearn: 0.2618383\ttotal: 13s\tremaining: 8.29s\n",
      "610:\tlearn: 0.2616686\ttotal: 13s\tremaining: 8.27s\n",
      "611:\tlearn: 0.2615385\ttotal: 13s\tremaining: 8.26s\n",
      "612:\tlearn: 0.2614758\ttotal: 13.1s\tremaining: 8.24s\n",
      "613:\tlearn: 0.2613571\ttotal: 13.1s\tremaining: 8.23s\n",
      "614:\tlearn: 0.2612867\ttotal: 13.1s\tremaining: 8.23s\n",
      "615:\tlearn: 0.2611772\ttotal: 13.2s\tremaining: 8.21s\n",
      "616:\tlearn: 0.2610168\ttotal: 13.2s\tremaining: 8.2s\n",
      "617:\tlearn: 0.2608697\ttotal: 13.2s\tremaining: 8.18s\n",
      "618:\tlearn: 0.2608036\ttotal: 13.2s\tremaining: 8.15s\n",
      "619:\tlearn: 0.2606575\ttotal: 13.3s\tremaining: 8.13s\n",
      "620:\tlearn: 0.2605469\ttotal: 13.3s\tremaining: 8.1s\n",
      "621:\tlearn: 0.2605103\ttotal: 13.3s\tremaining: 8.07s\n",
      "622:\tlearn: 0.2604093\ttotal: 13.3s\tremaining: 8.05s\n",
      "623:\tlearn: 0.2603061\ttotal: 13.3s\tremaining: 8.02s\n",
      "624:\tlearn: 0.2601656\ttotal: 13.3s\tremaining: 7.99s\n",
      "625:\tlearn: 0.2601333\ttotal: 13.3s\tremaining: 7.97s\n",
      "626:\tlearn: 0.2601029\ttotal: 13.4s\tremaining: 7.94s\n",
      "627:\tlearn: 0.2599882\ttotal: 13.4s\tremaining: 7.92s\n",
      "628:\tlearn: 0.2599082\ttotal: 13.4s\tremaining: 7.89s\n",
      "629:\tlearn: 0.2598117\ttotal: 13.4s\tremaining: 7.87s\n",
      "630:\tlearn: 0.2596435\ttotal: 13.4s\tremaining: 7.85s\n",
      "631:\tlearn: 0.2595964\ttotal: 13.4s\tremaining: 7.82s\n",
      "632:\tlearn: 0.2595266\ttotal: 13.4s\tremaining: 7.8s\n",
      "633:\tlearn: 0.2594195\ttotal: 13.5s\tremaining: 7.77s\n",
      "634:\tlearn: 0.2591930\ttotal: 13.5s\tremaining: 7.75s\n",
      "635:\tlearn: 0.2590810\ttotal: 13.5s\tremaining: 7.72s\n",
      "636:\tlearn: 0.2589970\ttotal: 13.5s\tremaining: 7.69s\n",
      "637:\tlearn: 0.2588856\ttotal: 13.5s\tremaining: 7.67s\n",
      "638:\tlearn: 0.2587750\ttotal: 13.6s\tremaining: 7.66s\n",
      "639:\tlearn: 0.2586171\ttotal: 13.6s\tremaining: 7.64s\n",
      "640:\tlearn: 0.2585193\ttotal: 13.6s\tremaining: 7.62s\n",
      "641:\tlearn: 0.2583867\ttotal: 13.6s\tremaining: 7.59s\n",
      "642:\tlearn: 0.2582863\ttotal: 13.6s\tremaining: 7.57s\n",
      "643:\tlearn: 0.2581372\ttotal: 13.7s\tremaining: 7.55s\n",
      "644:\tlearn: 0.2579251\ttotal: 13.7s\tremaining: 7.53s\n",
      "645:\tlearn: 0.2577752\ttotal: 13.7s\tremaining: 7.5s\n",
      "646:\tlearn: 0.2576412\ttotal: 13.7s\tremaining: 7.48s\n",
      "647:\tlearn: 0.2575566\ttotal: 13.7s\tremaining: 7.47s\n",
      "648:\tlearn: 0.2573930\ttotal: 13.8s\tremaining: 7.44s\n",
      "649:\tlearn: 0.2572704\ttotal: 13.8s\tremaining: 7.42s\n",
      "650:\tlearn: 0.2570296\ttotal: 13.8s\tremaining: 7.4s\n",
      "651:\tlearn: 0.2569126\ttotal: 13.8s\tremaining: 7.38s\n",
      "652:\tlearn: 0.2567738\ttotal: 13.8s\tremaining: 7.36s\n",
      "653:\tlearn: 0.2566672\ttotal: 13.9s\tremaining: 7.33s\n",
      "654:\tlearn: 0.2566095\ttotal: 13.9s\tremaining: 7.3s\n",
      "655:\tlearn: 0.2565346\ttotal: 13.9s\tremaining: 7.28s\n",
      "656:\tlearn: 0.2563989\ttotal: 13.9s\tremaining: 7.26s\n",
      "657:\tlearn: 0.2563562\ttotal: 13.9s\tremaining: 7.23s\n",
      "658:\tlearn: 0.2563158\ttotal: 13.9s\tremaining: 7.21s\n",
      "659:\tlearn: 0.2562450\ttotal: 13.9s\tremaining: 7.18s\n",
      "660:\tlearn: 0.2561509\ttotal: 14s\tremaining: 7.16s\n",
      "661:\tlearn: 0.2561287\ttotal: 14s\tremaining: 7.13s\n",
      "662:\tlearn: 0.2560219\ttotal: 14s\tremaining: 7.11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663:\tlearn: 0.2558822\ttotal: 14s\tremaining: 7.09s\n",
      "664:\tlearn: 0.2558561\ttotal: 14s\tremaining: 7.06s\n",
      "665:\tlearn: 0.2558148\ttotal: 14s\tremaining: 7.04s\n",
      "666:\tlearn: 0.2557519\ttotal: 14.1s\tremaining: 7.01s\n",
      "667:\tlearn: 0.2556353\ttotal: 14.1s\tremaining: 6.99s\n",
      "668:\tlearn: 0.2554326\ttotal: 14.1s\tremaining: 6.99s\n",
      "669:\tlearn: 0.2553224\ttotal: 14.1s\tremaining: 6.97s\n",
      "670:\tlearn: 0.2552024\ttotal: 14.2s\tremaining: 6.94s\n",
      "671:\tlearn: 0.2550904\ttotal: 14.2s\tremaining: 6.92s\n",
      "672:\tlearn: 0.2549866\ttotal: 14.2s\tremaining: 6.9s\n",
      "673:\tlearn: 0.2548117\ttotal: 14.2s\tremaining: 6.88s\n",
      "674:\tlearn: 0.2546442\ttotal: 14.2s\tremaining: 6.85s\n",
      "675:\tlearn: 0.2545537\ttotal: 14.2s\tremaining: 6.83s\n",
      "676:\tlearn: 0.2544196\ttotal: 14.3s\tremaining: 6.8s\n",
      "677:\tlearn: 0.2542344\ttotal: 14.3s\tremaining: 6.78s\n",
      "678:\tlearn: 0.2541067\ttotal: 14.3s\tremaining: 6.76s\n",
      "679:\tlearn: 0.2540710\ttotal: 14.3s\tremaining: 6.74s\n",
      "680:\tlearn: 0.2539997\ttotal: 14.3s\tremaining: 6.71s\n",
      "681:\tlearn: 0.2539887\ttotal: 14.4s\tremaining: 6.69s\n",
      "682:\tlearn: 0.2538104\ttotal: 14.4s\tremaining: 6.67s\n",
      "683:\tlearn: 0.2537753\ttotal: 14.4s\tremaining: 6.64s\n",
      "684:\tlearn: 0.2536822\ttotal: 14.4s\tremaining: 6.62s\n",
      "685:\tlearn: 0.2536229\ttotal: 14.4s\tremaining: 6.6s\n",
      "686:\tlearn: 0.2534753\ttotal: 14.4s\tremaining: 6.58s\n",
      "687:\tlearn: 0.2533196\ttotal: 14.5s\tremaining: 6.55s\n",
      "688:\tlearn: 0.2531777\ttotal: 14.5s\tremaining: 6.53s\n",
      "689:\tlearn: 0.2530040\ttotal: 14.5s\tremaining: 6.51s\n",
      "690:\tlearn: 0.2528405\ttotal: 14.5s\tremaining: 6.5s\n",
      "691:\tlearn: 0.2527785\ttotal: 14.6s\tremaining: 6.48s\n",
      "692:\tlearn: 0.2526873\ttotal: 14.6s\tremaining: 6.46s\n",
      "693:\tlearn: 0.2526415\ttotal: 14.6s\tremaining: 6.44s\n",
      "694:\tlearn: 0.2526079\ttotal: 14.6s\tremaining: 6.42s\n",
      "695:\tlearn: 0.2525169\ttotal: 14.7s\tremaining: 6.4s\n",
      "696:\tlearn: 0.2523726\ttotal: 14.7s\tremaining: 6.38s\n",
      "697:\tlearn: 0.2522819\ttotal: 14.7s\tremaining: 6.36s\n",
      "698:\tlearn: 0.2521490\ttotal: 14.7s\tremaining: 6.34s\n",
      "699:\tlearn: 0.2519896\ttotal: 14.7s\tremaining: 6.31s\n",
      "700:\tlearn: 0.2518647\ttotal: 14.8s\tremaining: 6.29s\n",
      "701:\tlearn: 0.2517231\ttotal: 14.8s\tremaining: 6.27s\n",
      "702:\tlearn: 0.2515792\ttotal: 14.8s\tremaining: 6.25s\n",
      "703:\tlearn: 0.2514665\ttotal: 14.8s\tremaining: 6.23s\n",
      "704:\tlearn: 0.2513777\ttotal: 14.8s\tremaining: 6.21s\n",
      "705:\tlearn: 0.2512697\ttotal: 14.9s\tremaining: 6.19s\n",
      "706:\tlearn: 0.2511831\ttotal: 14.9s\tremaining: 6.17s\n",
      "707:\tlearn: 0.2511056\ttotal: 14.9s\tremaining: 6.15s\n",
      "708:\tlearn: 0.2510267\ttotal: 14.9s\tremaining: 6.13s\n",
      "709:\tlearn: 0.2509325\ttotal: 15s\tremaining: 6.11s\n",
      "710:\tlearn: 0.2508169\ttotal: 15s\tremaining: 6.09s\n",
      "711:\tlearn: 0.2506883\ttotal: 15s\tremaining: 6.06s\n",
      "712:\tlearn: 0.2506145\ttotal: 15s\tremaining: 6.04s\n",
      "713:\tlearn: 0.2505681\ttotal: 15s\tremaining: 6.02s\n",
      "714:\tlearn: 0.2504598\ttotal: 15.1s\tremaining: 6.01s\n",
      "715:\tlearn: 0.2503634\ttotal: 15.1s\tremaining: 5.99s\n",
      "716:\tlearn: 0.2503060\ttotal: 15.1s\tremaining: 5.97s\n",
      "717:\tlearn: 0.2501643\ttotal: 15.1s\tremaining: 5.95s\n",
      "718:\tlearn: 0.2500743\ttotal: 15.2s\tremaining: 5.92s\n",
      "719:\tlearn: 0.2499191\ttotal: 15.2s\tremaining: 5.9s\n",
      "720:\tlearn: 0.2498352\ttotal: 15.2s\tremaining: 5.88s\n",
      "721:\tlearn: 0.2498037\ttotal: 15.2s\tremaining: 5.85s\n",
      "722:\tlearn: 0.2496889\ttotal: 15.2s\tremaining: 5.83s\n",
      "723:\tlearn: 0.2495478\ttotal: 15.2s\tremaining: 5.81s\n",
      "724:\tlearn: 0.2494892\ttotal: 15.3s\tremaining: 5.79s\n",
      "725:\tlearn: 0.2493963\ttotal: 15.3s\tremaining: 5.77s\n",
      "726:\tlearn: 0.2492822\ttotal: 15.3s\tremaining: 5.75s\n",
      "727:\tlearn: 0.2491515\ttotal: 15.3s\tremaining: 5.72s\n",
      "728:\tlearn: 0.2489828\ttotal: 15.3s\tremaining: 5.7s\n",
      "729:\tlearn: 0.2488798\ttotal: 15.3s\tremaining: 5.67s\n",
      "730:\tlearn: 0.2487365\ttotal: 15.4s\tremaining: 5.65s\n",
      "731:\tlearn: 0.2486494\ttotal: 15.4s\tremaining: 5.63s\n",
      "732:\tlearn: 0.2485294\ttotal: 15.4s\tremaining: 5.61s\n",
      "733:\tlearn: 0.2483956\ttotal: 15.4s\tremaining: 5.58s\n",
      "734:\tlearn: 0.2482692\ttotal: 15.4s\tremaining: 5.56s\n",
      "735:\tlearn: 0.2481741\ttotal: 15.4s\tremaining: 5.53s\n",
      "736:\tlearn: 0.2480244\ttotal: 15.4s\tremaining: 5.51s\n",
      "737:\tlearn: 0.2479352\ttotal: 15.5s\tremaining: 5.49s\n",
      "738:\tlearn: 0.2478406\ttotal: 15.5s\tremaining: 5.46s\n",
      "739:\tlearn: 0.2477882\ttotal: 15.5s\tremaining: 5.44s\n",
      "740:\tlearn: 0.2477024\ttotal: 15.5s\tremaining: 5.42s\n",
      "741:\tlearn: 0.2475663\ttotal: 15.5s\tremaining: 5.39s\n",
      "742:\tlearn: 0.2473708\ttotal: 15.5s\tremaining: 5.37s\n",
      "743:\tlearn: 0.2473069\ttotal: 15.5s\tremaining: 5.35s\n",
      "744:\tlearn: 0.2471163\ttotal: 15.6s\tremaining: 5.33s\n",
      "745:\tlearn: 0.2470140\ttotal: 15.6s\tremaining: 5.3s\n",
      "746:\tlearn: 0.2468501\ttotal: 15.6s\tremaining: 5.28s\n",
      "747:\tlearn: 0.2467103\ttotal: 15.6s\tremaining: 5.25s\n",
      "748:\tlearn: 0.2466290\ttotal: 15.6s\tremaining: 5.23s\n",
      "749:\tlearn: 0.2465235\ttotal: 15.6s\tremaining: 5.21s\n",
      "750:\tlearn: 0.2464018\ttotal: 15.6s\tremaining: 5.18s\n",
      "751:\tlearn: 0.2462744\ttotal: 15.7s\tremaining: 5.16s\n",
      "752:\tlearn: 0.2461153\ttotal: 15.7s\tremaining: 5.14s\n",
      "753:\tlearn: 0.2460540\ttotal: 15.7s\tremaining: 5.12s\n",
      "754:\tlearn: 0.2459085\ttotal: 15.7s\tremaining: 5.09s\n",
      "755:\tlearn: 0.2457918\ttotal: 15.7s\tremaining: 5.07s\n",
      "756:\tlearn: 0.2457078\ttotal: 15.7s\tremaining: 5.05s\n",
      "757:\tlearn: 0.2456330\ttotal: 15.7s\tremaining: 5.02s\n",
      "758:\tlearn: 0.2454858\ttotal: 15.8s\tremaining: 5s\n",
      "759:\tlearn: 0.2453566\ttotal: 15.8s\tremaining: 4.98s\n",
      "760:\tlearn: 0.2451973\ttotal: 15.8s\tremaining: 4.95s\n",
      "761:\tlearn: 0.2450399\ttotal: 15.8s\tremaining: 4.93s\n",
      "762:\tlearn: 0.2449280\ttotal: 15.8s\tremaining: 4.91s\n",
      "763:\tlearn: 0.2448252\ttotal: 15.8s\tremaining: 4.88s\n",
      "764:\tlearn: 0.2447548\ttotal: 15.8s\tremaining: 4.86s\n",
      "765:\tlearn: 0.2446443\ttotal: 15.8s\tremaining: 4.84s\n",
      "766:\tlearn: 0.2445020\ttotal: 15.9s\tremaining: 4.82s\n",
      "767:\tlearn: 0.2443189\ttotal: 15.9s\tremaining: 4.79s\n",
      "768:\tlearn: 0.2442046\ttotal: 15.9s\tremaining: 4.78s\n",
      "769:\tlearn: 0.2440999\ttotal: 15.9s\tremaining: 4.75s\n",
      "770:\tlearn: 0.2440416\ttotal: 15.9s\tremaining: 4.73s\n",
      "771:\tlearn: 0.2438968\ttotal: 15.9s\tremaining: 4.71s\n",
      "772:\tlearn: 0.2437504\ttotal: 16s\tremaining: 4.68s\n",
      "773:\tlearn: 0.2436242\ttotal: 16s\tremaining: 4.66s\n",
      "774:\tlearn: 0.2434850\ttotal: 16s\tremaining: 4.64s\n",
      "775:\tlearn: 0.2433960\ttotal: 16s\tremaining: 4.62s\n",
      "776:\tlearn: 0.2432533\ttotal: 16s\tremaining: 4.59s\n",
      "777:\tlearn: 0.2431063\ttotal: 16.1s\tremaining: 4.58s\n",
      "778:\tlearn: 0.2430025\ttotal: 16.1s\tremaining: 4.56s\n",
      "779:\tlearn: 0.2429038\ttotal: 16.1s\tremaining: 4.54s\n",
      "780:\tlearn: 0.2427796\ttotal: 16.1s\tremaining: 4.52s\n",
      "781:\tlearn: 0.2426429\ttotal: 16.1s\tremaining: 4.49s\n",
      "782:\tlearn: 0.2425533\ttotal: 16.1s\tremaining: 4.47s\n",
      "783:\tlearn: 0.2424651\ttotal: 16.1s\tremaining: 4.45s\n",
      "784:\tlearn: 0.2423384\ttotal: 16.2s\tremaining: 4.42s\n",
      "785:\tlearn: 0.2422803\ttotal: 16.2s\tremaining: 4.4s\n",
      "786:\tlearn: 0.2421909\ttotal: 16.2s\tremaining: 4.38s\n",
      "787:\tlearn: 0.2421107\ttotal: 16.2s\tremaining: 4.36s\n",
      "788:\tlearn: 0.2420876\ttotal: 16.2s\tremaining: 4.33s\n",
      "789:\tlearn: 0.2420118\ttotal: 16.2s\tremaining: 4.31s\n",
      "790:\tlearn: 0.2418817\ttotal: 16.2s\tremaining: 4.29s\n",
      "791:\tlearn: 0.2417349\ttotal: 16.3s\tremaining: 4.27s\n",
      "792:\tlearn: 0.2416716\ttotal: 16.3s\tremaining: 4.25s\n",
      "793:\tlearn: 0.2415923\ttotal: 16.3s\tremaining: 4.23s\n",
      "794:\tlearn: 0.2415026\ttotal: 16.3s\tremaining: 4.21s\n",
      "795:\tlearn: 0.2414349\ttotal: 16.3s\tremaining: 4.19s\n",
      "796:\tlearn: 0.2413489\ttotal: 16.4s\tremaining: 4.17s\n",
      "797:\tlearn: 0.2412775\ttotal: 16.4s\tremaining: 4.14s\n",
      "798:\tlearn: 0.2411755\ttotal: 16.4s\tremaining: 4.12s\n",
      "799:\tlearn: 0.2410593\ttotal: 16.4s\tremaining: 4.1s\n",
      "800:\tlearn: 0.2409279\ttotal: 16.4s\tremaining: 4.08s\n",
      "801:\tlearn: 0.2408762\ttotal: 16.5s\tremaining: 4.06s\n",
      "802:\tlearn: 0.2408296\ttotal: 16.5s\tremaining: 4.05s\n",
      "803:\tlearn: 0.2406988\ttotal: 16.6s\tremaining: 4.04s\n",
      "804:\tlearn: 0.2405663\ttotal: 16.6s\tremaining: 4.02s\n",
      "805:\tlearn: 0.2404752\ttotal: 16.6s\tremaining: 4.01s\n",
      "806:\tlearn: 0.2404468\ttotal: 16.7s\tremaining: 3.99s\n",
      "807:\tlearn: 0.2403727\ttotal: 16.7s\tremaining: 3.96s\n",
      "808:\tlearn: 0.2402381\ttotal: 16.7s\tremaining: 3.94s\n",
      "809:\tlearn: 0.2401579\ttotal: 16.7s\tremaining: 3.92s\n",
      "810:\tlearn: 0.2399682\ttotal: 16.7s\tremaining: 3.9s\n",
      "811:\tlearn: 0.2399270\ttotal: 16.7s\tremaining: 3.88s\n",
      "812:\tlearn: 0.2398376\ttotal: 16.8s\tremaining: 3.85s\n",
      "813:\tlearn: 0.2397434\ttotal: 16.8s\tremaining: 3.83s\n",
      "814:\tlearn: 0.2396808\ttotal: 16.8s\tremaining: 3.81s\n",
      "815:\tlearn: 0.2396195\ttotal: 16.8s\tremaining: 3.79s\n",
      "816:\tlearn: 0.2395114\ttotal: 16.8s\tremaining: 3.77s\n",
      "817:\tlearn: 0.2393817\ttotal: 16.8s\tremaining: 3.74s\n",
      "818:\tlearn: 0.2392396\ttotal: 16.8s\tremaining: 3.72s\n",
      "819:\tlearn: 0.2390916\ttotal: 16.8s\tremaining: 3.7s\n",
      "820:\tlearn: 0.2389371\ttotal: 16.9s\tremaining: 3.68s\n",
      "821:\tlearn: 0.2388224\ttotal: 16.9s\tremaining: 3.65s\n",
      "822:\tlearn: 0.2387209\ttotal: 16.9s\tremaining: 3.63s\n",
      "823:\tlearn: 0.2385808\ttotal: 16.9s\tremaining: 3.61s\n",
      "824:\tlearn: 0.2384419\ttotal: 16.9s\tremaining: 3.59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825:\tlearn: 0.2383071\ttotal: 16.9s\tremaining: 3.57s\n",
      "826:\tlearn: 0.2381941\ttotal: 17s\tremaining: 3.55s\n",
      "827:\tlearn: 0.2380772\ttotal: 17s\tremaining: 3.53s\n",
      "828:\tlearn: 0.2379849\ttotal: 17s\tremaining: 3.52s\n",
      "829:\tlearn: 0.2378676\ttotal: 17.1s\tremaining: 3.49s\n",
      "830:\tlearn: 0.2378064\ttotal: 17.1s\tremaining: 3.47s\n",
      "831:\tlearn: 0.2376908\ttotal: 17.1s\tremaining: 3.45s\n",
      "832:\tlearn: 0.2375504\ttotal: 17.1s\tremaining: 3.43s\n",
      "833:\tlearn: 0.2374205\ttotal: 17.1s\tremaining: 3.4s\n",
      "834:\tlearn: 0.2373506\ttotal: 17.1s\tremaining: 3.38s\n",
      "835:\tlearn: 0.2371954\ttotal: 17.1s\tremaining: 3.36s\n",
      "836:\tlearn: 0.2370614\ttotal: 17.2s\tremaining: 3.34s\n",
      "837:\tlearn: 0.2369580\ttotal: 17.2s\tremaining: 3.32s\n",
      "838:\tlearn: 0.2368292\ttotal: 17.2s\tremaining: 3.3s\n",
      "839:\tlearn: 0.2367026\ttotal: 17.2s\tremaining: 3.27s\n",
      "840:\tlearn: 0.2365890\ttotal: 17.2s\tremaining: 3.25s\n",
      "841:\tlearn: 0.2365635\ttotal: 17.2s\tremaining: 3.23s\n",
      "842:\tlearn: 0.2364125\ttotal: 17.2s\tremaining: 3.21s\n",
      "843:\tlearn: 0.2362874\ttotal: 17.3s\tremaining: 3.19s\n",
      "844:\tlearn: 0.2361422\ttotal: 17.3s\tremaining: 3.17s\n",
      "845:\tlearn: 0.2360457\ttotal: 17.3s\tremaining: 3.15s\n",
      "846:\tlearn: 0.2359197\ttotal: 17.3s\tremaining: 3.12s\n",
      "847:\tlearn: 0.2358421\ttotal: 17.3s\tremaining: 3.1s\n",
      "848:\tlearn: 0.2357212\ttotal: 17.3s\tremaining: 3.08s\n",
      "849:\tlearn: 0.2356027\ttotal: 17.3s\tremaining: 3.06s\n",
      "850:\tlearn: 0.2354707\ttotal: 17.4s\tremaining: 3.04s\n",
      "851:\tlearn: 0.2353732\ttotal: 17.4s\tremaining: 3.02s\n",
      "852:\tlearn: 0.2352905\ttotal: 17.4s\tremaining: 3s\n",
      "853:\tlearn: 0.2352196\ttotal: 17.4s\tremaining: 2.97s\n",
      "854:\tlearn: 0.2350797\ttotal: 17.4s\tremaining: 2.95s\n",
      "855:\tlearn: 0.2349409\ttotal: 17.4s\tremaining: 2.93s\n",
      "856:\tlearn: 0.2348740\ttotal: 17.5s\tremaining: 2.91s\n",
      "857:\tlearn: 0.2347543\ttotal: 17.5s\tremaining: 2.89s\n",
      "858:\tlearn: 0.2346241\ttotal: 17.5s\tremaining: 2.87s\n",
      "859:\tlearn: 0.2345421\ttotal: 17.5s\tremaining: 2.85s\n",
      "860:\tlearn: 0.2344262\ttotal: 17.5s\tremaining: 2.83s\n",
      "861:\tlearn: 0.2343188\ttotal: 17.5s\tremaining: 2.81s\n",
      "862:\tlearn: 0.2341863\ttotal: 17.6s\tremaining: 2.79s\n",
      "863:\tlearn: 0.2340818\ttotal: 17.6s\tremaining: 2.77s\n",
      "864:\tlearn: 0.2339453\ttotal: 17.6s\tremaining: 2.75s\n",
      "865:\tlearn: 0.2338901\ttotal: 17.6s\tremaining: 2.72s\n",
      "866:\tlearn: 0.2338267\ttotal: 17.6s\tremaining: 2.7s\n",
      "867:\tlearn: 0.2337022\ttotal: 17.6s\tremaining: 2.68s\n",
      "868:\tlearn: 0.2335879\ttotal: 17.6s\tremaining: 2.66s\n",
      "869:\tlearn: 0.2335610\ttotal: 17.7s\tremaining: 2.64s\n",
      "870:\tlearn: 0.2334845\ttotal: 17.7s\tremaining: 2.62s\n",
      "871:\tlearn: 0.2334486\ttotal: 17.7s\tremaining: 2.6s\n",
      "872:\tlearn: 0.2332975\ttotal: 17.7s\tremaining: 2.58s\n",
      "873:\tlearn: 0.2331727\ttotal: 17.7s\tremaining: 2.55s\n",
      "874:\tlearn: 0.2330751\ttotal: 17.7s\tremaining: 2.53s\n",
      "875:\tlearn: 0.2329639\ttotal: 17.8s\tremaining: 2.51s\n",
      "876:\tlearn: 0.2328372\ttotal: 17.8s\tremaining: 2.49s\n",
      "877:\tlearn: 0.2327245\ttotal: 17.8s\tremaining: 2.47s\n",
      "878:\tlearn: 0.2325671\ttotal: 17.8s\tremaining: 2.45s\n",
      "879:\tlearn: 0.2324994\ttotal: 17.8s\tremaining: 2.43s\n",
      "880:\tlearn: 0.2323610\ttotal: 17.8s\tremaining: 2.41s\n",
      "881:\tlearn: 0.2323203\ttotal: 17.8s\tremaining: 2.39s\n",
      "882:\tlearn: 0.2321136\ttotal: 17.9s\tremaining: 2.37s\n",
      "883:\tlearn: 0.2320028\ttotal: 17.9s\tremaining: 2.35s\n",
      "884:\tlearn: 0.2319607\ttotal: 17.9s\tremaining: 2.32s\n",
      "885:\tlearn: 0.2318480\ttotal: 17.9s\tremaining: 2.3s\n",
      "886:\tlearn: 0.2317525\ttotal: 17.9s\tremaining: 2.28s\n",
      "887:\tlearn: 0.2316314\ttotal: 17.9s\tremaining: 2.26s\n",
      "888:\tlearn: 0.2315448\ttotal: 17.9s\tremaining: 2.24s\n",
      "889:\tlearn: 0.2313987\ttotal: 18s\tremaining: 2.22s\n",
      "890:\tlearn: 0.2313388\ttotal: 18s\tremaining: 2.2s\n",
      "891:\tlearn: 0.2312619\ttotal: 18s\tremaining: 2.18s\n",
      "892:\tlearn: 0.2311124\ttotal: 18s\tremaining: 2.16s\n",
      "893:\tlearn: 0.2310392\ttotal: 18.1s\tremaining: 2.14s\n",
      "894:\tlearn: 0.2309382\ttotal: 18.1s\tremaining: 2.12s\n",
      "895:\tlearn: 0.2308639\ttotal: 18.1s\tremaining: 2.1s\n",
      "896:\tlearn: 0.2307184\ttotal: 18.1s\tremaining: 2.08s\n",
      "897:\tlearn: 0.2306054\ttotal: 18.1s\tremaining: 2.06s\n",
      "898:\tlearn: 0.2305095\ttotal: 18.1s\tremaining: 2.04s\n",
      "899:\tlearn: 0.2304097\ttotal: 18.1s\tremaining: 2.01s\n",
      "900:\tlearn: 0.2303378\ttotal: 18.1s\tremaining: 1.99s\n",
      "901:\tlearn: 0.2302677\ttotal: 18.2s\tremaining: 1.97s\n",
      "902:\tlearn: 0.2301487\ttotal: 18.2s\tremaining: 1.95s\n",
      "903:\tlearn: 0.2300017\ttotal: 18.2s\tremaining: 1.93s\n",
      "904:\tlearn: 0.2299399\ttotal: 18.2s\tremaining: 1.91s\n",
      "905:\tlearn: 0.2298943\ttotal: 18.2s\tremaining: 1.89s\n",
      "906:\tlearn: 0.2297948\ttotal: 18.2s\tremaining: 1.87s\n",
      "907:\tlearn: 0.2296768\ttotal: 18.3s\tremaining: 1.85s\n",
      "908:\tlearn: 0.2295725\ttotal: 18.3s\tremaining: 1.83s\n",
      "909:\tlearn: 0.2295074\ttotal: 18.3s\tremaining: 1.81s\n",
      "910:\tlearn: 0.2294802\ttotal: 18.3s\tremaining: 1.79s\n",
      "911:\tlearn: 0.2294323\ttotal: 18.3s\tremaining: 1.77s\n",
      "912:\tlearn: 0.2293513\ttotal: 18.3s\tremaining: 1.75s\n",
      "913:\tlearn: 0.2292713\ttotal: 18.3s\tremaining: 1.73s\n",
      "914:\tlearn: 0.2292339\ttotal: 18.4s\tremaining: 1.71s\n",
      "915:\tlearn: 0.2291452\ttotal: 18.4s\tremaining: 1.69s\n",
      "916:\tlearn: 0.2290897\ttotal: 18.4s\tremaining: 1.66s\n",
      "917:\tlearn: 0.2289657\ttotal: 18.4s\tremaining: 1.64s\n",
      "918:\tlearn: 0.2288704\ttotal: 18.4s\tremaining: 1.62s\n",
      "919:\tlearn: 0.2287575\ttotal: 18.4s\tremaining: 1.6s\n",
      "920:\tlearn: 0.2286850\ttotal: 18.4s\tremaining: 1.58s\n",
      "921:\tlearn: 0.2285646\ttotal: 18.5s\tremaining: 1.56s\n",
      "922:\tlearn: 0.2284414\ttotal: 18.5s\tremaining: 1.54s\n",
      "923:\tlearn: 0.2283436\ttotal: 18.5s\tremaining: 1.52s\n",
      "924:\tlearn: 0.2282339\ttotal: 18.5s\tremaining: 1.5s\n",
      "925:\tlearn: 0.2281706\ttotal: 18.5s\tremaining: 1.48s\n",
      "926:\tlearn: 0.2279876\ttotal: 18.6s\tremaining: 1.46s\n",
      "927:\tlearn: 0.2278066\ttotal: 18.6s\tremaining: 1.44s\n",
      "928:\tlearn: 0.2277802\ttotal: 18.6s\tremaining: 1.42s\n",
      "929:\tlearn: 0.2277107\ttotal: 18.6s\tremaining: 1.4s\n",
      "930:\tlearn: 0.2276140\ttotal: 18.6s\tremaining: 1.38s\n",
      "931:\tlearn: 0.2274656\ttotal: 18.7s\tremaining: 1.36s\n",
      "932:\tlearn: 0.2273768\ttotal: 18.7s\tremaining: 1.34s\n",
      "933:\tlearn: 0.2273262\ttotal: 18.7s\tremaining: 1.32s\n",
      "934:\tlearn: 0.2271734\ttotal: 18.7s\tremaining: 1.3s\n",
      "935:\tlearn: 0.2271184\ttotal: 18.7s\tremaining: 1.28s\n",
      "936:\tlearn: 0.2270239\ttotal: 18.7s\tremaining: 1.26s\n",
      "937:\tlearn: 0.2269967\ttotal: 18.7s\tremaining: 1.24s\n",
      "938:\tlearn: 0.2268652\ttotal: 18.8s\tremaining: 1.22s\n",
      "939:\tlearn: 0.2268430\ttotal: 18.8s\tremaining: 1.2s\n",
      "940:\tlearn: 0.2267539\ttotal: 18.8s\tremaining: 1.18s\n",
      "941:\tlearn: 0.2266609\ttotal: 18.8s\tremaining: 1.16s\n",
      "942:\tlearn: 0.2265552\ttotal: 18.8s\tremaining: 1.14s\n",
      "943:\tlearn: 0.2264706\ttotal: 18.8s\tremaining: 1.12s\n",
      "944:\tlearn: 0.2263516\ttotal: 18.9s\tremaining: 1.1s\n",
      "945:\tlearn: 0.2262324\ttotal: 18.9s\tremaining: 1.08s\n",
      "946:\tlearn: 0.2261177\ttotal: 18.9s\tremaining: 1.06s\n",
      "947:\tlearn: 0.2260486\ttotal: 18.9s\tremaining: 1.04s\n",
      "948:\tlearn: 0.2259760\ttotal: 18.9s\tremaining: 1.02s\n",
      "949:\tlearn: 0.2258750\ttotal: 18.9s\tremaining: 997ms\n",
      "950:\tlearn: 0.2258097\ttotal: 19s\tremaining: 978ms\n",
      "951:\tlearn: 0.2257922\ttotal: 19s\tremaining: 958ms\n",
      "952:\tlearn: 0.2257041\ttotal: 19s\tremaining: 937ms\n",
      "953:\tlearn: 0.2256813\ttotal: 19s\tremaining: 917ms\n",
      "954:\tlearn: 0.2256069\ttotal: 19s\tremaining: 897ms\n",
      "955:\tlearn: 0.2255693\ttotal: 19.1s\tremaining: 877ms\n",
      "956:\tlearn: 0.2254655\ttotal: 19.1s\tremaining: 857ms\n",
      "957:\tlearn: 0.2253768\ttotal: 19.1s\tremaining: 837ms\n",
      "958:\tlearn: 0.2252357\ttotal: 19.1s\tremaining: 818ms\n",
      "959:\tlearn: 0.2251161\ttotal: 19.1s\tremaining: 798ms\n",
      "960:\tlearn: 0.2250041\ttotal: 19.2s\tremaining: 778ms\n",
      "961:\tlearn: 0.2249026\ttotal: 19.2s\tremaining: 758ms\n",
      "962:\tlearn: 0.2248051\ttotal: 19.2s\tremaining: 738ms\n",
      "963:\tlearn: 0.2246717\ttotal: 19.2s\tremaining: 718ms\n",
      "964:\tlearn: 0.2246008\ttotal: 19.3s\tremaining: 699ms\n",
      "965:\tlearn: 0.2245442\ttotal: 19.3s\tremaining: 679ms\n",
      "966:\tlearn: 0.2244084\ttotal: 19.3s\tremaining: 659ms\n",
      "967:\tlearn: 0.2243460\ttotal: 19.3s\tremaining: 639ms\n",
      "968:\tlearn: 0.2242588\ttotal: 19.3s\tremaining: 618ms\n",
      "969:\tlearn: 0.2242292\ttotal: 19.3s\tremaining: 598ms\n",
      "970:\tlearn: 0.2241373\ttotal: 19.4s\tremaining: 578ms\n",
      "971:\tlearn: 0.2240602\ttotal: 19.4s\tremaining: 559ms\n",
      "972:\tlearn: 0.2240011\ttotal: 19.4s\tremaining: 539ms\n",
      "973:\tlearn: 0.2238902\ttotal: 19.4s\tremaining: 519ms\n",
      "974:\tlearn: 0.2236980\ttotal: 19.5s\tremaining: 499ms\n",
      "975:\tlearn: 0.2236142\ttotal: 19.5s\tremaining: 479ms\n",
      "976:\tlearn: 0.2235442\ttotal: 19.5s\tremaining: 460ms\n",
      "977:\tlearn: 0.2234572\ttotal: 19.5s\tremaining: 440ms\n",
      "978:\tlearn: 0.2233559\ttotal: 19.6s\tremaining: 420ms\n",
      "979:\tlearn: 0.2232140\ttotal: 19.6s\tremaining: 400ms\n",
      "980:\tlearn: 0.2231004\ttotal: 19.6s\tremaining: 380ms\n",
      "981:\tlearn: 0.2230190\ttotal: 19.7s\tremaining: 360ms\n",
      "982:\tlearn: 0.2229091\ttotal: 19.7s\tremaining: 340ms\n",
      "983:\tlearn: 0.2228850\ttotal: 19.7s\tremaining: 320ms\n",
      "984:\tlearn: 0.2227563\ttotal: 19.7s\tremaining: 300ms\n",
      "985:\tlearn: 0.2226438\ttotal: 19.7s\tremaining: 280ms\n",
      "986:\tlearn: 0.2225243\ttotal: 19.7s\tremaining: 260ms\n",
      "987:\tlearn: 0.2224586\ttotal: 19.8s\tremaining: 240ms\n",
      "988:\tlearn: 0.2224347\ttotal: 19.8s\tremaining: 220ms\n",
      "989:\tlearn: 0.2223176\ttotal: 19.8s\tremaining: 200ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990:\tlearn: 0.2222145\ttotal: 19.8s\tremaining: 180ms\n",
      "991:\tlearn: 0.2222088\ttotal: 19.8s\tremaining: 160ms\n",
      "992:\tlearn: 0.2221311\ttotal: 19.8s\tremaining: 140ms\n",
      "993:\tlearn: 0.2220622\ttotal: 19.8s\tremaining: 120ms\n",
      "994:\tlearn: 0.2219249\ttotal: 19.8s\tremaining: 99.7ms\n",
      "995:\tlearn: 0.2218348\ttotal: 19.9s\tremaining: 79.8ms\n",
      "996:\tlearn: 0.2217158\ttotal: 19.9s\tremaining: 59.8ms\n",
      "997:\tlearn: 0.2215683\ttotal: 19.9s\tremaining: 39.9ms\n",
      "998:\tlearn: 0.2214831\ttotal: 19.9s\tremaining: 19.9ms\n",
      "999:\tlearn: 0.2213397\ttotal: 19.9s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x182fa440c50>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_e_1.fit(X_train_sk, y_train)\n",
    "clf_e_2.fit(X_train_sk, y_train)\n",
    "clf_e_4.fit(X_train_sk, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (clf_e_1.predict_proba(X_train_sk)[:, 1] + clf_e_2.predict_proba(X_train_sk)[: ,1]\n",
    "+ clf_e_4.predict_proba(X_train_sk)[:, 1])/ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7292938099389713\n",
      "0.8142292490118578\n",
      "0.8463269358041032\n",
      "0.8672416230736604\n",
      "0.8845919610231426\n",
      "0.8507560815253123\n",
      "0.783446307527649\n"
     ]
    }
   ],
   "source": [
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(res > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7218831734960768\n",
      "0.8022626660108214\n",
      "0.8348843392714703\n",
      "0.8626720183486238\n",
      "0.8769444016633298\n",
      "0.8344549125168237\n",
      "0.7709578127829079\n"
     ]
    }
   ],
   "source": [
    "# for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     print(f1_score(y_train, np.array(res > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8769444016633298"
      ]
     },
     "execution_count": 1584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, np.array(res > 0.5, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VotingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-3fd28ce43c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvotingC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rfc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_e_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'extc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_e_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'catboost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_e_4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'soft'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvotingC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvotingC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VotingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "votingC = VotingClassifier(estimators=[('rfc', clf_e_1), ('extc', clf_e_2), ('catboost', clf_e_4)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(X_train_sk, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'votingC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-cc97fe3c9c3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvotingC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mth\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'votingC' is not defined"
     ]
    }
   ],
   "source": [
    "vote = votingC.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(vote > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7215438290449192\n",
      "0.7999017319739591\n",
      "0.8332446808510638\n",
      "0.8620146152743946\n",
      "0.8755774561133354\n",
      "0.8341455217610486\n",
      "0.7680843329698291\n"
     ]
    }
   ],
   "source": [
    "# vote = votingC.predict_proba(X_train_sk)[:, 1]\n",
    "# for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     print(f1_score(y_train, np.array(vote > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pls = np.array(votingC.predict_proba(X_test_sk)[:, 1] > 0.5, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/egor/Desktop/subpobeda.csv\", \"w\", encoding='utf-8') as outfile:\n",
    "    outfile.write(str(\"pair_id,target\\n\"))\n",
    "    for i in range(len(y_pls)):\n",
    "        outfile.write(str(pair_ids[i]) + str(\",\") + str(y_pls[i]) + str(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для DBSCAN(0.475, samples = 7):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.82 при 5 соседях для косинуса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.848095724500219 при 15 соседях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8509769612131818 при 20 соседях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8545427858505797 при 25 соседях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для DBSCAN(0.6, samples = 7):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8305378831694621 на 5 соседях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8496447730897491 на 15 соседях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.858557902403496 на 25 соседях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min_samples = 8 дает получше скор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_titles = DBSCAN(0.7, metric=\"cosine\", min_samples=8):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На 25 соседях 0.8600523712540006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_titles = DBSCAN(0.7, metric=\"cosine\", min_samples=7) на 25 соседях дает 0.8593886462882097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_titles = DBSCAN(0.7, metric=\"cosine\", min_samples=9) на 25 соседях дает 0.8584289240598229"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_titles = DBSCAN(0.65, metric=\"cosine\", min_samples=8) на 25 соседях дает 0.8568099053168244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_titles = DBSCAN(0.6, metric=\"cosine\", min_samples=8) на 25 соседях дает 0.8567264247194286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Добавил соседей по текстам:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN(0.7, metric=\"cosine\", min_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей 0.8733713951105255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 15 соседей 0.8819013876586951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 25 соседей 0.8833702882483371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model_titles = DBSCAN(0.65, metric=\"cosine\", min_samples=8) на 25 соседях дает 0.8568099053168244 -  взял это, но количество соседей никак не учитывается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей model_texts = DBSCAN(0.05, metric=\"cosine\", min_samples=5) дает 0.857598607888631"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей model_texts = DBSCAN(0.15, metric=\"cosine\", min_samples=5) дает 0.8583466511695481 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей model_texts = DBSCAN(0.2, metric=\"cosine\", min_samples=5) дает 0.8596746077861709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей model_texts = DBSCAN(0.3, metric=\"cosine\", min_samples=5) дает 0.8609368159929958"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей model_texts = DBSCAN(0.4, metric=\"cosine\", min_samples=5) дает 0.8622248141128445 но это мне не нравится, потому что похоже на переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей model_texts = DBSCAN(0.4, metric=\"cosine\", min_samples=6) дает 0.8609734771203731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 3 соседей model_texts = DBSCAN(0.4, metric=\"cosine\", min_samples=4) дает 0.8611030055442077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Попрубую подключить одно косинусное расстояние для текстов, посмотрим, что будет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 1 соседей model_texts = DBSCAN(0.3, metric=\"cosine\", min_samples=4) дает 0.8664050007268499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 2 соседей model_texts = DBSCAN(0.3, metric=\"cosine\", min_samples=4) дает 0.8681672025723474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 20 соседей model_texts = DBSCAN(0.3, metric=\"cosine\", min_samples=4) дает 0.880437999408109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я не верю в расстояния между текстами!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (clf_e_1.predict_proba(X_test_sk)[:, 1] + clf_e_2.predict_proba(X_test_sk)[: ,1]\n",
    "+ clf_e_4.predict_proba(X_test_sk)[:, 1])/ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(test > 0.5, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/egor/Desktop/resultBest.csv\", \"w\", encoding='utf-8') as outfile:\n",
    "    outfile.write(str(\"pair_id,target\\n\"))\n",
    "    for i in range(len(y_test)):\n",
    "        outfile.write(str(pair_ids[i]) + str(\",\") + str(y_test[i]) + str(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лучше не использовать fasttext фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Уже прям боевая валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7248156019410812"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtC = ExtraTreesClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"f1\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsExtC.fit(X_train_sk,y_train)\n",
    "\n",
    "ExtC_best = gsExtC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsExtC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6997279765641348\n",
      "0.763045540796964\n",
      "0.7904626150058313\n",
      "0.8030409686048148\n",
      "0.8038733476790655\n",
      "0.7604113977406844\n",
      "0.6935332708528584\n"
     ]
    }
   ],
   "source": [
    "res_extra = ExtC_best.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(res_extra > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7316912972085386\n",
      "0.8194977112458246\n",
      "0.8700549818962049\n",
      "0.9059112588524353\n",
      "0.9059512796793093\n",
      "0.8810184429574017\n",
      "0.8109917209793905\n"
     ]
    }
   ],
   "source": [
    "# res_extra = ExtC_best.predict_proba(X_train_sk)[:, 1]\n",
    "# for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     print(f1_score(y_train, np.array(res_extra > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=4)]: Done 270 out of 270 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7239176588743648"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RFC Parameters tunning \n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"f1\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsRFC.fit(X_train_sk,y_train)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716020451640392\n",
      "0.7954958227388303\n",
      "0.8361300471945463\n",
      "0.8592592592592592\n",
      "0.8655848132271893\n",
      "0.8375642940102871\n",
      "0.7584953661639106\n"
     ]
    }
   ],
   "source": [
    "res_forest = RFC_best.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(res_forest > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740732543985836\n",
      "0.8313403089187842\n",
      "0.8862291554599248\n",
      "0.9165945165945167\n",
      "0.9215716251337716\n",
      "0.8956283271495402\n",
      "0.8236319275008713\n"
     ]
    }
   ],
   "source": [
    "# res_forest = RFC_best.predict_proba(X_train_sk)[:, 1]\n",
    "# for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     print(f1_score(y_train, np.array(res_forest > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=4)]: Done 360 out of 360 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7265828642763722"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient boosting tunning\n",
    "\n",
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8],\n",
    "              'min_samples_leaf': [100,150],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"f1\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsGBC.fit(X_train_sk,y_train)\n",
    "\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsGBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6947816826411075\n",
      "0.7555342826373102\n",
      "0.7779658809740851\n",
      "0.7902616482440186\n",
      "0.7862909367859863\n",
      "0.7430102126234722\n",
      "0.6759880686055183\n"
     ]
    }
   ],
   "source": [
    "res_grad = GBC_best.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(res_grad > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6821523708044752\n",
      "0.7382695307812313\n",
      "0.7585216142092205\n",
      "0.769209315297727\n",
      "0.7599632127529123\n",
      "0.7222880352005415\n",
      "0.6601686972820994\n"
     ]
    }
   ],
   "source": [
    "# res_grad = GBC_best.predict_proba(X_train_sk)[:, 1]\n",
    "# for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     print(f1_score(y_train, np.array(res_grad > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  9.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-388bcdcd0bf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mgsCatBoost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCatBoost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCB_param_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgsCatBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mCB_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsCatBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Catboost tunning\n",
    "\n",
    "CatBoost = catboost.CatBoostClassifier()\n",
    "CB_param_grid = {'depth' : [3, 4, 5, 6],\n",
    "              'l2_leaf_reg' : [21500, 22000, 25000, 28000, 28500],\n",
    "              'scale_pos_weight': [1, 2, 2.4] \n",
    "              }\n",
    "\n",
    "gsCatBoost = GridSearchCV(CatBoost,param_grid = CB_param_grid, cv=kfold, scoring=\"f1\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsCatBoost.fit(X_train_sk, y_train)\n",
    "\n",
    "CB_best = gsCatBoost.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsCatBoost.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_best = gsCatBoost.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_catB = CB_best.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(res_catB > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617937049677664\n",
      "0.6789383561643836\n",
      "0.7002039428959891\n",
      "0.7330012453300125\n",
      "0.7423881387344452\n",
      "0.7415062287655719\n",
      "0.7136648961854177\n"
     ]
    }
   ],
   "source": [
    "# res_catB = CB_best.predict_proba(X_train_sk)[:, 1]\n",
    "# for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     print(f1_score(y_train, np.array(res_catB > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=4)]: Done 240 out of 240 | elapsed:   47.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7425616026285582"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "XGB = xgb.XGBClassifier()\n",
    "xgb_param_grid = {'alpha' : [0.01, 0.1],\n",
    "              'n_estimators' : [10,20,30],\n",
    "              'eval_metric': ['auc'],\n",
    "              'max_depth': [4, 6],\n",
    "              'scale_pos_weight': [1.5, 1.7, 2, 2.4] \n",
    "              }\n",
    "\n",
    "gsXGB = GridSearchCV(XGB,param_grid = xgb_param_grid, cv=kfold, scoring=\"f1\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsXGB.fit(X_train_sk,y_train)\n",
    "\n",
    "XGB_best = gsXGB.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsXGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6612179806638094\n",
      "0.7154202514890802\n",
      "0.7562093079334459\n",
      "0.7730441518202943\n",
      "0.7855678556785569\n",
      "0.775323910482921\n",
      "0.7352746525479815\n"
     ]
    }
   ],
   "source": [
    "res_XGB = XGB_best.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(res_XGB > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-4a097712a99d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StackingClassifier' from 'sklearn.ensemble' (C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('rf', RFC_best), ('et', ExtC_best), ('gb', GBC_best), ('cb', XGB_best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingClassifier(estimators=estimators, final_estimator=MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.fit(X_train_sk, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_res = stack.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(stack_res > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6913659793814433\n",
      "0.7452807060554058\n",
      "0.759767687434002\n",
      "0.7695955369595537\n",
      "0.7710879734419798\n",
      "0.735483870967742\n",
      "0.6928738108059593\n"
     ]
    }
   ],
   "source": [
    "# stack_res = stack.predict_proba(X_train_sk)[:, 1]\n",
    "# for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     print(f1_score(y_train, np.array(stack_res > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно подобрать порог!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pls = np.array(stack.predict_proba(X_test_sk)[:, 1] > 0.4, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1641,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/egor/Desktop/subpobeda.csv\", \"w\", encoding='utf-8') as outfile:\n",
    "    outfile.write(str(\"pair_id,target\\n\"))\n",
    "    for i in range(len(y_pls)):\n",
    "        outfile.write(str(pair_ids[i]) + str(\",\") + str(y_pls[i]) + str(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на Кэгле = 0.68162 - сильное переобучение - решил убрать расстояние между текстами. Было 25 cosine, 0.65, 8; 0.3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на Кэгле = 0.69587 без текстов но 25 cosine, 0.65, 8; 0.3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидации 0.7809; на кэгле - 0.729. Это на 15 фичах от Севы и 10 tf-idf фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-2586dce4368f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                        ], voting='soft', n_jobs=4)\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mvotingC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvotingC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker."
     ]
    }
   ],
   "source": [
    "votingC = VotingClassifier(estimators=[('rf', RFC_best), ('et', ExtC_best), ('gb', GBC_best), ('xgb', XGB_best),\n",
    "                                       ('stack', stack)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(X_train_sk, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6924516531503433\n",
      "0.7530892982047096\n",
      "0.7952544967470341\n",
      "0.8075388636676296\n",
      "0.8316212594908442\n",
      "0.81343886286545\n",
      "0.751706791232483\n"
     ]
    }
   ],
   "source": [
    "vote = votingC.predict_proba(X_train_sk)[:, 1]\n",
    "for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f1_score(y_train, np.array(vote > th, dtype=int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидация RandomForest + ExtraTree = 0.8157055925818604 на 25 фичах на titles и 3 на текстах. model_titles = DBSCAN(0.6, metric=\"cosine\", min_samples=8); model_texts = DBSCAN(0.1, metric=\"cosine\", min_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pls = np.array(votingC.predict_proba(X_test_sk)[:, 1] > 0.5, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1656,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/egor/Desktop/subpobeda.csv\", \"w\", encoding='utf-8') as outfile:\n",
    "    outfile.write(str(\"pair_id,target\\n\"))\n",
    "    for i in range(len(y_pls)):\n",
    "        outfile.write(str(pair_ids[i]) + str(\",\") + str(y_pls[i]) + str(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на Кэгле 0.69022 текстов но 25 cosine, 0.65, 8; 0.1, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У Вани на фичах без текстов на рандомфоресте и экстраТри 0.71 на кагле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У Вани на фичах с 20 текстами на рандомфоресте и экстраТри 0.706 на кагле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Три модельки на маленьком количестве фичей 0.71702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стекинг на 25 + 20 + 2 + 25 фичей от Севы и три модели  скор = 0.6992. Наверное из-за текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стекинг на маленьком количестве фичей скор = 0.71886"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без стекинга Голосование из 4 моделей: RandomForest, ExtraTrees, Градиентный бустинг, XGBoost 25 + 25 + 2 фичей  скор на кагле = 0.72434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Голосование над стекингом и еще 4 модели дает 0.72298 на 10 tf-idf фичах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Голосование из 5 моделей: Stacking, RandomForest, ExtraTrees, Градиентный бустинг, XGBoost 25 + 25 + 2 фичей скор на кагле = 0.7270"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Стекинг над 4 моделями 7 tf-idf фичей дал 0.734"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Голосование над 5 моделями включая стекинг дало 0.83 на валидации и 0.731 на кэгле. Это 15 фичей от Севы и 10 tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стекинг без голосования дало 0.7344 на кэгле, а на валидации 0.7688 на 5 tf-idf фичах и 25 Севиных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Стекинг на катбусте и еще 3 модели, final_esimator = MLPClassifier() на 15 фичах от Севы и 10 tf-idf на валидации 0.831, а на кэгле 0.73644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autokeras\n",
      "  Downloading autokeras-1.0.12-py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 975 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-tuner>=1.0.2\n",
      "  Downloading keras-tuner-1.0.2.tar.gz (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 721 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from autokeras) (20.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from autokeras) (0.22.2)\n",
      "Requirement already satisfied: tensorflow>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from autokeras) (2.3.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from autokeras) (0.24.2)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras) (1.18.5)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting terminaltables\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
      "Requirement already satisfied: colorama in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras) (0.4.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras) (4.48.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras) (2.24.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from keras-tuner>=1.0.2->autokeras) (1.4.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from packaging->autokeras) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from packaging->autokeras) (2.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->autokeras) (0.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (3.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (1.11.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (0.34.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (1.30.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: pytz>=2011k in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas->autokeras) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas->autokeras) (2.8.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.25.10)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->autokeras) (49.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.20.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
      "Building wheels for collected packages: keras-tuner, future, terminaltables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-py3-none-any.whl size=78936 sha256=5b8eacfd3d09dd47ffe5decadce22a2d57b62f0a46c588730b79fab7b168ed05\n",
      "  Stored in directory: /Users/egor/Library/Caches/pip/wheels/78/e2/80/7fe373cad54ad22b06d0d6204cbc29cead9e69bb2680327775\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=7c6f55f8556c75aaa3a92189474a1ffb6f2ca6f8c73e8020606f772f5a8b3dda\n",
      "  Stored in directory: /Users/egor/Library/Caches/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=9d9d12e13a5cd421f5588c17da0e5c9c02f47e7ed7c9da558a50df822f5241d9\n",
      "  Stored in directory: /Users/egor/Library/Caches/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
      "Successfully built keras-tuner future terminaltables\n",
      "Installing collected packages: future, tabulate, terminaltables, keras-tuner, autokeras\n",
      "Successfully installed autokeras-1.0.12 future-0.18.2 keras-tuner-1.0.2 tabulate-0.8.7 terminaltables-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 36)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690,)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 1)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y_train)[:,np.newaxis]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = pd.DataFrame(data=X_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11690 entries, 0 to 11689\n",
      "Data columns (total 37 columns):\n",
      "0     11690 non-null float64\n",
      "1     11690 non-null float64\n",
      "2     11690 non-null float64\n",
      "3     11690 non-null float64\n",
      "4     11690 non-null float64\n",
      "5     11690 non-null float64\n",
      "6     11690 non-null float64\n",
      "7     11690 non-null float64\n",
      "8     11690 non-null float64\n",
      "9     11690 non-null float64\n",
      "10    11690 non-null float64\n",
      "11    11690 non-null float64\n",
      "12    11690 non-null float64\n",
      "13    11690 non-null float64\n",
      "14    11690 non-null float64\n",
      "15    11690 non-null float64\n",
      "16    11690 non-null float64\n",
      "17    11690 non-null float64\n",
      "18    11690 non-null float64\n",
      "19    11690 non-null float64\n",
      "20    11690 non-null float64\n",
      "21    11690 non-null float64\n",
      "22    11690 non-null float64\n",
      "23    11690 non-null float64\n",
      "24    11690 non-null float64\n",
      "25    11690 non-null float64\n",
      "26    11690 non-null float64\n",
      "27    11690 non-null float64\n",
      "28    11690 non-null float64\n",
      "29    11690 non-null float64\n",
      "30    11690 non-null float64\n",
      "31    11690 non-null float64\n",
      "32    11690 non-null float64\n",
      "33    11690 non-null float64\n",
      "34    11690 non-null float64\n",
      "35    11690 non-null float64\n",
      "36    11690 non-null float64\n",
      "dtypes: float64(37)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "Train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.to_csv('train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614383</td>\n",
       "      <td>0.528873</td>\n",
       "      <td>0.509626</td>\n",
       "      <td>0.504905</td>\n",
       "      <td>0.501869</td>\n",
       "      <td>0.461926</td>\n",
       "      <td>0.449864</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653389</td>\n",
       "      <td>0.628512</td>\n",
       "      <td>0.580146</td>\n",
       "      <td>0.533492</td>\n",
       "      <td>0.457677</td>\n",
       "      <td>0.426910</td>\n",
       "      <td>0.407499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282926</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.260648</td>\n",
       "      <td>0.248446</td>\n",
       "      <td>0.230717</td>\n",
       "      <td>0.230373</td>\n",
       "      <td>0.228871</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188717</td>\n",
       "      <td>0.179073</td>\n",
       "      <td>0.151745</td>\n",
       "      <td>0.146303</td>\n",
       "      <td>0.135194</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>0.129261</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450056</td>\n",
       "      <td>0.424316</td>\n",
       "      <td>0.422547</td>\n",
       "      <td>0.414055</td>\n",
       "      <td>0.398026</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.339476</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...        27        28  \\\n",
       "0  4.0  4.0  3.0  3.0  3.0  2.0  2.0  2.0  2.0  2.0  ...  0.614383  0.528873   \n",
       "1  8.0  7.0  7.0  7.0  7.0  7.0  4.0  4.0  3.0  3.0  ...  0.653389  0.628512   \n",
       "2  2.0  2.0  2.0  2.0  2.0  2.0  2.0  1.0  1.0  1.0  ...  0.282926  0.263492   \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.188717  0.179073   \n",
       "4  2.0  2.0  2.0  2.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  0.450056  0.424316   \n",
       "\n",
       "         29        30        31        32        33   34   35   36  \n",
       "0  0.509626  0.504905  0.501869  0.461926  0.449864 -1.0  0.0  0.0  \n",
       "1  0.580146  0.533492  0.457677  0.426910  0.407499  0.0  0.0  0.0  \n",
       "2  0.260648  0.248446  0.230717  0.230373  0.228871 -1.0  0.0  0.0  \n",
       "3  0.151745  0.146303  0.135194  0.132056  0.129261 -1.0  0.0  0.0  \n",
       "4  0.422547  0.414055  0.398026  0.359367  0.339476 -1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "5        0.0\n",
       "6        0.0\n",
       "7        0.0\n",
       "8        0.0\n",
       "9        0.0\n",
       "10       0.0\n",
       "11       0.0\n",
       "12       0.0\n",
       "13       0.0\n",
       "14       0.0\n",
       "15       0.0\n",
       "16       0.0\n",
       "17       0.0\n",
       "18       0.0\n",
       "19       0.0\n",
       "20       0.0\n",
       "21       0.0\n",
       "22       0.0\n",
       "23       0.0\n",
       "24       0.0\n",
       "25       0.0\n",
       "26       0.0\n",
       "27       0.0\n",
       "28       1.0\n",
       "29       0.0\n",
       "        ... \n",
       "11660    0.0\n",
       "11661    0.0\n",
       "11662    0.0\n",
       "11663    1.0\n",
       "11664    1.0\n",
       "11665    0.0\n",
       "11666    0.0\n",
       "11667    0.0\n",
       "11668    0.0\n",
       "11669    0.0\n",
       "11670    1.0\n",
       "11671    1.0\n",
       "11672    0.0\n",
       "11673    0.0\n",
       "11674    0.0\n",
       "11675    0.0\n",
       "11676    0.0\n",
       "11677    0.0\n",
       "11678    0.0\n",
       "11679    0.0\n",
       "11680    0.0\n",
       "11681    0.0\n",
       "11682    0.0\n",
       "11683    0.0\n",
       "11684    0.0\n",
       "11685    0.0\n",
       "11686    0.0\n",
       "11687    0.0\n",
       "11688    0.0\n",
       "11689    0.0\n",
       "Name: 36, Length: 11690, dtype: float64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 20s]\n",
      "val_accuracy: 0.8517718315124512\n",
      "\n",
      "Best val_accuracy So Far: 0.8517718315124512\n",
      "Total elapsed time: 00h 01m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Layer multi_category_encoding is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.6887\n",
      "Epoch 2/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7407\n",
      "Epoch 3/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4903 - accuracy: 0.7815\n",
      "Epoch 4/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.8037\n",
      "Epoch 5/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8138\n",
      "Epoch 6/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8185\n",
      "Epoch 7/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8238\n",
      "Epoch 8/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4098 - accuracy: 0.8246\n",
      "Epoch 9/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4064 - accuracy: 0.8269\n",
      "Epoch 10/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8286\n",
      "Epoch 11/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.4010 - accuracy: 0.8293\n",
      "Epoch 12/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3995 - accuracy: 0.8300: 0s - loss: 0.4095 - accuracy\n",
      "Epoch 13/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3977 - accuracy: 0.8322\n",
      "Epoch 14/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3970 - accuracy: 0.8315\n",
      "Epoch 15/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3959 - accuracy: 0.8305\n",
      "Epoch 16/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8328\n",
      "Epoch 17/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3934 - accuracy: 0.8339: 0s - loss: 0.4006 - accu\n",
      "Epoch 18/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8332\n",
      "Epoch 19/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3913 - accuracy: 0.8338\n",
      "Epoch 20/20\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8334\n",
      "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 36)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x163417a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d93950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1652dc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165add840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d936a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d78378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d93268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165addae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x163417510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d78d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165a42bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165addc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d93d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165a42ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x161aef268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165a42950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d93ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x163417158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x161aefb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x161aeff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1652dc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d93c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x165a42e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x161473488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x161aef400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x161b15840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167d78950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "predicted_y = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1679551e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160ca56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160ca60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160ca5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1679557b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd11e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160ca69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd8268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167938ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160ca6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x164683ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160ca68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167938400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1646802f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x16071f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x167938e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x164680c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x16071f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x164680598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160ca5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x160cd1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "predicted_y_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7126715092816788"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predicted_y_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = predicted_y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = predicted_y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = np.array(predicted_y).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/egor/Desktop/resultBest.csv\", \"w\", encoding='utf-8') as outfile:\n",
    "    outfile.write(str(\"pair_id,target\\n\"))\n",
    "    for i in range(len(y_test)):\n",
    "        outfile.write(str(pair_ids[i]) + str(\",\") + str(predicted_y[i]) + str(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
